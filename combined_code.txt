**File Tree (Relevant Files Only)**
  .
    - viz.py
  data\raw
    - btc_usdt_1m_processed.csv
// File: viz.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from pathlib import Path
import plotly.graph_objects as go
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Add MinMaxScaler
from typing import Dict, List, Optional, Literal
import logging
from tqdm import tqdm
import plotly.express as px  # Import for interactive plots

# Configure robust logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("market_visualizer.log"), logging.StreamHandler()])
logger = logging.getLogger(__name__)

# Define the device
if torch.cuda.is_available():
    device = torch.device('cuda')
    torch.backends.cudnn.benchmark = True  # Enable cuDNN auto-tuner
    logger.info("CUDA is available. Running on GPU.")
else:
    device = torch.device('cpu')
    logger.info("CUDA is not available. Running on CPU.")

class HypersphericalEncoder(nn.Module):
    """GPU-accelerated hyperspherical encoder with proper normalization"""
    
    def __init__(
        self,
        projection_dim: int = 128,
        sequence_length: int = 60,
        n_price_features: int = 5,
        n_indicator_features: int = 4,
        temperature: float = 0.07,
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        price_scaler: StandardScaler = None,
        indicator_scaler: StandardScaler = None
    ):
        super(HypersphericalEncoder, self).__init__()
        self.projection_dim = projection_dim
        self.sequence_length = sequence_length
        self.n_price_features = n_price_features
        self.n_indicator_features = n_indicator_features
        self.temperature = temperature
        self.device = device
        
        # Assign scalers
        self.price_scaler = price_scaler
        self.indicator_scaler = indicator_scaler
        
        # Initialize neural network components
        self.projection1 = nn.Linear(
            n_price_features + n_indicator_features, 
            projection_dim * 2
        ).to(device)
        
        # Replace BatchNorm with LayerNorm
        self.layer_norm = nn.LayerNorm(projection_dim * 2).to(device)
        self.projection2 = nn.Linear(projection_dim * 2, projection_dim).to(device)
        
        # Set to eval mode and disable gradients
        self.eval()
        self._set_requires_grad(False)
    
    def _set_requires_grad(self, requires_grad: bool):
        """Set requires_grad for all parameters"""
        for param in self.parameters():
            param.requires_grad_(requires_grad)
    
    @torch.no_grad()
    def encode_batch(self, sequences: np.ndarray) -> torch.Tensor:
        """Encode a batch of sequences"""
        if sequences.ndim == 2:
            sequences = sequences.reshape(1, *sequences.shape)
            
        # Split and scale features
        price_data = sequences[:, :, :self.n_price_features]
        indicator_data = sequences[:, :, self.n_price_features:self.n_price_features + self.n_indicator_features]
        
        if self.price_scaler is None or self.indicator_scaler is None:
            raise ValueError("Scalers have not been fitted. Please fit scalers before encoding.")
        
        price_scaled = self.price_scaler.transform(price_data.reshape(-1, self.n_price_features))
        indicator_scaled = self.indicator_scaler.transform(indicator_data.reshape(-1, self.n_indicator_features))
        
        # Reshape back to batches
        price_scaled = price_scaled.reshape(sequences.shape[0], sequences.shape[1], -1)
        indicator_scaled = indicator_scaled.reshape(sequences.shape[0], sequences.shape[1], -1)
        
        # Get last timestep
        price_last = torch.FloatTensor(price_scaled[:, -1, :]).to(self.device)
        indicator_last = torch.FloatTensor(indicator_scaled[:, -1, :]).to(self.device)
        
        # Combine features
        combined = torch.cat([price_last, indicator_last], dim=1)
        
        # Project through network
        hidden = self.projection1(combined)
        hidden = F.relu(self.layer_norm(hidden))
        projected = self.projection2(hidden)
        
        # Apply temperature scaling and normalize
        scaled = projected / self.temperature
        normalized = F.normalize(scaled, p=2, dim=1)
        
        return normalized

class MarketVisualizer:
    """Visualization tools for market data and encoded states"""

    def __init__(
        self,
        data_path: str = "data/raw/btc_usdt_1m_processed.csv",
        batch_size: int = 256,  # Increased batch size for GPU utilization
        sequence_length: int = 64, # Increased sequence length for more context, adjust as needed
        hidden_size: int = 128,     # larger hypersphere embedding visualization
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        scaling_method: Literal["standard", "minmax"] = "standard"  # Add scaling method arg
    ):
        logger.info(f"Initializing MarketVisualizer with data from {data_path}")
        self.data_path = Path(data_path)
        self.batch_size = batch_size
        self.device = device
        self.sequence_length = sequence_length # Store sequence length
        self.hidden_size = hidden_size  # larger hypersphere embedding visualization
        self.scaling_method = scaling_method
        
        if not self.data_path.exists():
            raise FileNotFoundError(f"Data file not found: {data_path}")
        
        # Load data
        logger.info("Loading and preprocessing market data...")
        self.df = pd.read_csv(self.data_path)
        self.df['timestamp'] = pd.to_datetime(self.df['open_time'])
        self.df.set_index('timestamp', inplace=True)
        
        # Define price and additional feature columns
        self.price_columns = ['open', 'high', 'low', 'close', 'volume']
        self.indicator_columns = [
            'quote_asset_volume', 'number_of_trades',
            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume'
        ]
        
        # Convert columns to numeric
        logger.info("Converting data to numeric format...")
        all_numeric_columns = self.price_columns + self.indicator_columns
        for col in tqdm(all_numeric_columns, desc="Processing columns"):
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
        
        # Create analysis dataframe
        self.analysis_df = self.df[all_numeric_columns].copy()
        logger.info(f"Analysis dataframe shape: {self.analysis_df.shape}")
        
        # Initialize scalers based on scaling_method
        if self.scaling_method == "standard":
            self.price_scaler = StandardScaler()
            self.indicator_scaler = StandardScaler()
        elif self.scaling_method == "minmax":
            self.price_scaler = MinMaxScaler()
            self.indicator_scaler = MinMaxScaler()
        else:
            raise ValueError("Invalid scaling_method. Choose 'standard' or 'minmax'.")
        
        # Fit scalers
        self._fit_scalers()
        
        # Initialize encoder with fitted scalers
        self.encoder = HypersphericalEncoder(
            n_price_features=len(self.price_columns),
            n_indicator_features=len(self.indicator_columns),
            projection_dim=self.hidden_size,  # Larger embedding size for visualization
            sequence_length=self.sequence_length, # Pass sequence length to encoder
            device=device,
            price_scaler=self.price_scaler,
            indicator_scaler=self.indicator_scaler
        ).to(device)  # Move encoder to device
    
    def _fit_scalers(self):
        """Fit scalers on numeric data, handling NaN values"""
        logger.info("Creating sequences for scaler fitting...")
        
        sequences = []
        stride = 1000  # Use stride to reduce memory usage
        n_sequences = (len(self.analysis_df) - self.sequence_length) // stride
        
        for i in range(n_sequences):
            idx = i * stride
            sequence = self.analysis_df.iloc[idx:idx + self.sequence_length].values
            sequences.append(sequence)
        
        data_for_fit = np.array(sequences)
        logger.info(f"Created {len(sequences)} sequences of shape {sequences[0].shape}")
        
        # Fit scalers
        price_data = self.analysis_df[self.price_columns].values.reshape(-1, len(self.price_columns))
        indicator_data = self.analysis_df[self.indicator_columns].values.reshape(-1, len(self.indicator_columns))

        self.price_scaler.fit(np.nan_to_num(price_data))
        self.indicator_scaler.fit(np.nan_to_num(indicator_data))
        logger.info("Scalers fitted successfully")
    
    def visualize_hypersphere(self, n_samples: int = 10000, projection_method: str = 'pca', perplexity: int = 50):
        """Visualize encoded states in reduced dimensionality with hover information"""
        logger.info(f"Creating hypersphere visualization using {projection_method}")
        
        # Calculate number of batches
        max_samples = min(n_samples, len(self.analysis_df) - self.encoder.sequence_length)
        n_batches = (max_samples + self.batch_size - 1) // self.batch_size
        
        encoded_states = []
        logger.info(f"Encoding {max_samples} market states in batches...")
        
        for batch_idx in tqdm(range(n_batches), desc="Processing batches"):
            start_idx = batch_idx * self.batch_size
            end_idx = min(start_idx + self.batch_size, max_samples)
            
            # Prepare batch sequences
            batch_sequences = []
            for i in range(start_idx, end_idx):
                sequence = self.analysis_df.iloc[i:i + self.encoder.sequence_length].values
                batch_sequences.append(sequence)
            
            # Convert to numpy array and encode batch
            batch_array = np.array(batch_sequences)
            try:
                batch_encoded = self.encoder.encode_batch(batch_array)
                encoded_states.append(batch_encoded.cpu())
            except Exception as e:
                logger.error(f"Error encoding batch {batch_idx}: {str(e)}")
                continue
        
        if not encoded_states:
            raise ValueError("No states were successfully encoded")
        
        # Combine all encoded states
        all_states = torch.cat(encoded_states, dim=0).numpy()
        logger.info(f"Successfully encoded {len(all_states)} states")
        
        # Dimensionality Reduction + Hover Info
        if projection_method == 'pca':
            reducer = PCA(n_components=3)
            reduced_states = reducer.fit_transform(all_states)
            hover_data = {f"Feature {i+1}": all_states[:, i] for i in range(all_states.shape[1])}
        elif projection_method == 'tsne':
            reducer = TSNE(n_components=3, perplexity=perplexity, n_jobs=-1) # Use all CPU cores
            reduced_states = reducer.fit_transform(all_states)
            hover_data = {f"Feature {i+1}": all_states[:, i] for i in range(all_states.shape[1])}
        else:
            raise ValueError("Invalid projection method. Choose 'pca' or 'tsne'.")

        # Interactive Plot with Plotly Express
        fig = px.scatter_3d(
            x=reduced_states[:, 0],
            y=reduced_states[:, 1],
            z=reduced_states[:, 2],
            color=np.arange(len(reduced_states)),  # Color based on sample index
            hover_data=hover_data, # Show high-dimensional encoded info as well
            title=f'Encoded States Visualization ({projection_method.upper()})'
        )

        return fig

def main():
    try:
        viz = MarketVisualizer(sequence_length=128, hidden_size=256, scaling_method="minmax") # Example: Use MinMaxScaler
        
        # Create output directory
        output_dir = Path("visualizations")
        output_dir.mkdir(exist_ok=True)
        logger.info(f"Created output directory: {output_dir}")
        
        # Create and save visualizations
        logger.info("Creating hypersphere visualization...")
        hypersphere_fig = viz.visualize_hypersphere(n_samples=10000, projection_method='tsne', perplexity=50)
        hypersphere_fig.write_html(output_dir / "hypersphere_tsne.html")
        
        logger.info("Visualizations completed successfully")
        print("\nVisualizations saved to 'visualizations' directory")
    
    except Exception as e:
        logger.error(f"Error creating visualizations: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    main()


// File: data\raw\btc_usdt_1m_processed.csv
// Snippet:
                open_time    open    high     low   close  volume                       close_time  quote_asset_volume  number_of_trades  taker_buy_base_asset_volume  taker_buy_quote_asset_volume  ignore  rsi_6  rsi_14  rsi_24      macd  macd_signal  macd_hist  bb_upper  bb_lower       ema_5      ema_10      ema_20      ema_60     ema_120
2020-01-01 00:00:00+00:00 7189.43 7190.52 7177.00 7182.44 246.092 2020-01-01 00:00:59.999000+00:00        1.767430e+06               336                       46.630                  334813.19820       0    0.0     0.0     0.0  0.000000     0.000000   0.000000       NaN       NaN 7182.440000 7182.440000 7182.440000 7182.440000 7182.440000
2020-01-01 00:01:00+00:00 7182.43 7182.44 7178.75 7179.01  70.909 2020-01-01 00:01:59.999000+00:00        5.091458e+05               140                       32.597                  234063.27884       0    0.0     0.0     0.0 -0.273618    -0.054724  -0.218895       NaN       NaN 7181.296667 7181.816364 7182.113333 7182.327541 7182.383306
2020-01-01 00:02:00+00:00 7179.01 7179.01 7175.25 7177.93  99.420 2020-01-01 00:02:59.999000+00:00        7.135396e+05               148                       16.311                  117066.92118       0    0.0     0.0     0.0 -0.571027    -0.157984  -0.413043       NaN       NaN 7180.174444 7181.109752 7181.714921 7182.183359 7182.309697
2020-01-01 00:03:00+00:00 7177.77 7182.60 7177.00 7181.11  69.330 2020-01-01 00:03:59.999000+00:00        4.977934e+05               104                       43.723                  313920.02981       0    0.0     0.0     0.0 -0.543857    -0.235159  -0.308698       NaN       NaN 7180.486296 7181.109797 7181.657309 7182.148167 7182.289868
2020-01-01 00:04:00+00:00 7179.10 7179.10 7172.94 7175.25  97.368 2020-01-01 00:04:59.999000+00:00        6.986274e+05               193                       36.616                  262734.68999       0    0.0     0.0     0.0 -0.983837    -0.384895  -0.598942       NaN       NaN 7178.740864 7180.044379 7181.047089 7181.921998 7182.173506

