// File: data\data_processor.py
import asyncio

class DataProcessor:
    def __init__(self, storage, indicator_calculator, error_handler, config):
        self.storage = storage
        self.indicator_calculator = indicator_calculator
        self.error_handler = error_handler
        self.config = config

    async def process_data(self, data_batch):
        """Processes kline data and applies indicators asynchronously."""
        processed_data = {}
        for data in data_batch:
            try:
                kline_data = self._extract_kline_data(data)
                timeframe = self._get_timeframe(data)
                if timeframe not in processed_data:
                    processed_data[timeframe] = []
                processed_data[timeframe].append(kline_data)
            except Exception as e:
                self.error_handler.handle_error(f"Error extracting kline data: {e}", exc_info=True)

        try:
            indicators = await self._calculate_indicators_async(processed_data)
            unified_feed = self._create_unified_feed(processed_data, indicators)
            await self.storage.store_data(unified_feed)
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating indicators or storing data: {e}", exc_info=True)

    async def _calculate_indicators_async(self, processed_data):
        """Calculates indicators asynchronously."""
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self.indicator_calculator.calculate_indicators, processed_data)

    def _extract_kline_data(self, data):
        # Extract kline data (fill with your logic)
        return {
            'open': data['d']['k']['o'],
            'high': data['d']['k']['h'],
            'low': data['d']['k']['l'],
            'close': data['d']['k']['c'],
            'volume': data['d']['k']['v'],
            'close_time': data['d']['k']['T']
        }

    def _get_timeframe(self, data):
        # Extract timeframe (assuming format is 'spot@public.kline.v3.api@BTCUSDT@kline_1m')
        return data.get('c', '').split('@')[-1].split('_')[-1]

    def _create_unified_feed(self, klines, indicators):
        """Combines kline data and indicators into a unified feed."""
        unified_feed = {}
        for timeframe, data in klines.items():
            unified_feed[timeframe] = {
                'price': [entry['close'] for entry in data],
                'volume': [entry['volume'] for entry in data],
                'open': [entry['open'] for entry in data],
                'high': [entry['high'] for entry in data],
                'low': [entry['low'] for entry in data],
                'close_time': [entry['close_time'] for entry in data],
                'indicators': indicators.get(timeframe, {})
            }
        return unified_feed


// File: data\indicator_calculations.py
import pandas as pd
from finta import TA
from .error_handler import ErrorHandler
from typing import Dict, Any, List
import concurrent.futures

class IndicatorCalculator:
    def __init__(self, error_handler: ErrorHandler):
        """
        Initializes the IndicatorCalculator with an error handler.
        Args:
            error_handler (ErrorHandler): Instance to handle errors during calculations.
        """
        self.error_handler = error_handler

    def calculate_indicators(self, symbol: str, data: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, Any]]:
        """
        Calculates indicators for all timeframes.
        Args:
            symbol (str): The trading symbol (e.g., 'BTC_USDT').
            data (Dict[str, pd.DataFrame]): Dictionary where keys are timeframes and values are DataFrames.
        Returns:
            Dict[str, Dict[str, Any]]: Dictionary of indicators keyed by timeframe.
        """
        indicators = {}
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {executor.submit(self._calculate_for_timeframe, symbol, timeframe, df): timeframe for timeframe, df in data.items()}
                for future in concurrent.futures.as_completed(futures):
                    timeframe = futures[future]
                    try:
                        indicators[timeframe] = future.result()
                    except Exception as e:
                        self.error_handler.handle_error(f"Error calculating indicators for {symbol} {timeframe}: {e}", exc_info=True)
        except Exception as e:
            self.error_handler.handle_error(f"Error in calculate_indicators: {e}", exc_info=True)
        return indicators

    def _calculate_for_timeframe(self, symbol: str, timeframe: str, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Helper function to calculate indicators for a specific timeframe.
        Args:
            symbol (str): The trading symbol (e.g., 'BTC_USDT').
            timeframe (str): The timeframe being processed.
            df (pd.DataFrame): DataFrame containing OHLC data for the timeframe.
        Returns:
            Dict[str, Any]: Calculated indicators for the timeframe.
        """
        indicators = {}
        try:
            # Ensure dataframe has the required columns
            required_columns = ['open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"Missing required columns in {timeframe} data for {symbol}: {df.columns}")

            indicators['rsi'] = self.calculate_rsi(df)
            indicators['macd'] = self.calculate_macd(df)
            indicators['fibonacci'] = self.calculate_fibonacci(df)
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating indicators for {symbol} {timeframe}: {e}", exc_info=True)
        return indicators

    def calculate_rsi(self, df: pd.DataFrame) -> List[float]:
        """
        Calculates the RSI (Relative Strength Index).
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            List[float]: RSI values.
        """
        try:
            rsi_values = TA.RSI(df).fillna(0).tolist()
            return rsi_values
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating RSI: {e}", exc_info=True)
            return []

    def calculate_macd(self, df: pd.DataFrame) -> Dict[str, List[float]]:
        """
        Calculates the MACD (Moving Average Convergence Divergence).
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            Dict[str, List[float]]: MACD values, signal line, and histogram.
        """
        try:
            macd_values = TA.MACD(df).fillna(0)
            return {
                'macd': macd_values['MACD'].tolist(),
                'macd_signal': macd_values['SIGNAL'].tolist(),
                'macd_hist': macd_values['HISTOGRAM'].tolist()
            }
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating MACD: {e}", exc_info=True)
            return {'macd': [], 'macd_signal': [], 'macd_hist': []}

    def calculate_fibonacci(self, df: pd.DataFrame) -> Dict[str, float]:
        """
        Calculates Fibonacci Retracement levels manually.
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            Dict[str, float]: Fibonacci retracement levels.
        """
        try:
            high = df['high'].max()
            low = df['low'].min()
            diff = high - low
            fib_levels = {
                "23.6%": high - 0.236 * diff,
                "38.2%": high - 0.382 * diff,
                "50.0%": high - 0.5 * diff,
                "61.8%": high - 0.618 * diff,
                "78.6%": high - 0.786 * diff
            }
            return fib_levels
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating Fibonacci Retracement: {e}", exc_info=True)
            return {}


// File: data\mexc_websocket_connector.py
import os
import json
import websockets
import asyncio
from dotenv import load_dotenv

load_dotenv()

class MexcWebsocketConnector:
    def __init__(self, data_queue):
        self.ws_url = os.getenv("MEXC_WS_URL", "wss://wbs.mexc.com/ws")
        self.api_key = os.getenv("MEXC_API_KEY")
        self.api_secret = os.getenv("MEXC_API_SECRET")
        self.reconnect_delay = 5.0
        self.data_queue = data_queue

    async def connect(self):
        while True:
            try:
                async with websockets.connect(self.ws_url) as ws:
                    await self._subscribe(ws)
                    await self._receive_batched_klines(ws)
            except Exception as e:
                print(f"WebSocket connection error: {e}")
                await asyncio.sleep(self.reconnect_delay)

    async def _subscribe(self, ws):
        subscribe_message = {
            "method": "SUBSCRIBE",
            "params": ["spot@public.kline.v3.api@BTCUSDT@kline_1m", "spot@public.kline.v3.api@BTCUSDT@kline_5m"],
            "id": 1
        }
        await ws.send(json.dumps(subscribe_message))

    async def _receive_batched_klines(self, ws):
        """Receives and processes kline data in batches."""
        kline_batch = []
        while True:
            try:
                message = await ws.recv()
                data = json.loads(message)
                if "spot@public.kline.v3.api" in data.get("c", ""):
                    kline_batch.append(data)
                else:
                    if kline_batch:
                        await self.data_queue.put(kline_batch)
                        kline_batch = []  # Reset batch
            except Exception as e:
                print(f"Error receiving kline data: {e}")
                break


// File: data\__init__.py
from .mexc_websocket_connector import MexcWebsocketConnector
from .data_processor import DataProcessor
from .storage.data_storage import DataStorage

__all__ = ['MexcWebsocketConnector', 'DataProcessor', 'WebSocketManager', 'DataStorage']


// File: data\storage\data_storage.py
import asyncio
import pandas as pd
import os

class DataStorage:
    def __init__(self, storage_path="data_storage"):
        self.storage_path = storage_path
        os.makedirs(self.storage_path, exist_ok=True)

    async def store_data(self, unified_feed):
        """Stores unified feed data asynchronously."""
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, self._store_data_sync, unified_feed)

    def _store_data_sync(self, unified_feed):
        """Synchronous helper function for data storage."""
        symbol = "BTC_USDT"  # Assuming single symbol; adjust if needed.
        for timeframe, content in unified_feed.items():
            df = pd.DataFrame(content)  # Create DataFrame from content
            filename = f"{symbol}_{timeframe}.csv"
            filepath = os.path.join(self.storage_path, filename)
            df.to_csv(filepath, index=False)
            print(f"Data stored in {filepath}")


// File: data\storage\__init__.py


