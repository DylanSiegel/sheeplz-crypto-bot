Here are the enhancements inspired by the HOVER paper's **policy distillation** and **multi-mode strategies**, tailored for your current code:

---

### **1. Policy Distillation**  
**Purpose**: Train specialized policies for specific market modes and merge them into a unified generalist policy.

#### Suggested Enhancements:
- Add **oracle policies** (e.g., `MetaSACActorOracle`) trained on distinct tasks:
   - **Momentum Mode**: Focus on high-frequency trend-following.
   - **Reversal Mode**: Prioritize mean-reverting trades.
   - **Volatility Mode**: Adjust risk under volatile conditions.
- Implement **distillation**:
   - Add a module `PolicyDistiller` that averages or minimizes KL divergence between the specialist and generalist policies.

**Code Integration**:  
Update `networks.py` with a distiller module:  
```python
class PolicyDistiller(nn.Module):
    def __init__(self, specialist_policies: List[nn.Module]):
        super().__init__()
        self.specialists = nn.ModuleList(specialist_policies)

    def forward(self, state, time_step):
        outputs = [policy(state, time_step) for policy in self.specialists]
        mu_avg = torch.mean(torch.stack([out[0] for out in outputs]), dim=0)
        log_sigma_avg = torch.mean(torch.stack([out[1] for out in outputs]), dim=0)
        return mu_avg, log_sigma_avg
```
In `agent.py`, integrate the distiller into the actor selection.

---

### **2. Multi-Mode Command Spaces**  
**Purpose**: Enable the agent to handle diverse objectives dynamically during training.

#### Suggested Enhancements:
- Introduce **mode masks** to dynamically adjust reward weights.
- Update **`MetaController`** to output:
   - Reward scaling factors: `r_scaling_momentum`, `r_scaling_reversal`, etc.
   - Adaptive hyperparameters based on detected market regime.

**Code Integration**:
Update `MetaController`:
```python
def forward(self, x: torch.Tensor, reward_stats: torch.Tensor) -> Tuple:
    outputs = self.mlp(torch.cat([x, reward_stats], dim=-1))
    return torch.sigmoid(outputs[:, :5]), torch.softmax(outputs[:, 5:], dim=-1)
```
- First 5 outputs adjust hyperparameters.
- Next outputs act as reward scaling factors.

Integrate reward scaling in `compute_q_targets`:
```python
q_target = r_scaling[0] * rewards + r_scaling[1] * q_target
```

---

### **3. Adaptive Task Switching**  
**Purpose**: Seamlessly switch between strategies based on detected market signals.

#### Suggested Enhancements:
- Integrate a **Market Mode Classifier**:
   - Train a lightweight CNN/LSTM on market data to predict market mode (bullish, bearish, sideways).
   - Use the prediction to activate relevant masks or reward adjustments dynamically.

**Code Integration**:  
Add a simple mode classifier to `networks.py`:
```python
class MarketModeClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim=3):  # 3 market modes
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim),
            nn.Softmax(dim=-1)
        )
    
    def forward(self, x):
        return self.net(x)  # Returns probabilities for market modes
```
Integrate into `MetaSACAgent` to toggle rewards or loss adjustments.

---

### **4. Sim-to-Real Transfer (Noise Augmentation)**  
**Purpose**: Improve generalization of the agent.

#### Suggested Enhancements:
- Add **Gaussian noise** to state inputs during training:
   ```python
   noisy_states = states + torch.randn_like(states) * self.config.noise_std
   ```
- Vary volatility in simulations using **randomized replay buffer sampling**.

Update `config.py`:
```python
noise_std: float = 0.01  # Standard deviation for state noise
```

---

### **5. Efficient Gradient Updates**  
**Purpose**: Prevent overfitting and improve gradient stability.

#### Suggested Enhancements:
- Replace **Adam** optimizers with **RAdam** or **Lookahead** for smoother convergence:
```python
from torch.optim import RAdam, Lookahead
self.actor_optimizer = Lookahead(RAdam(self.actor.parameters(), lr=self.config.lr))
```
- Clip gradients dynamically based on market volatility.

---

### **6. Hierarchical Policy Training**  
- Implement **high-level policy** to decide between **meta-controller adjustments** and **actor execution**.
- Use **hierarchical critic networks** that share some parameters between levels.

---

### **Summary of Enhancements**
1. **Policy Distillation**: Add `PolicyDistiller` to merge specialist policies.
2. **Multi-Mode Command Spaces**: Integrate reward scaling factors from `MetaController`.
3. **Adaptive Task Switching**: Train a market mode classifier to toggle strategies.
4. **Sim-to-Real Transfer**: Use noise augmentation and volatility randomization.
5. **Efficient Optimization**: Adopt advanced optimizers like RAdam/Lookahead.
6. **Hierarchical Training**: Separate high-level meta-control from low-level policy execution.

These additions will align your code more closely with the HOVER breakthroughs while enhancing training efficiency and generalization. Would you like me to prototype any specific component? ðŸš€
**File Tree (Relevant Files Only)**
  .
    - agent.py
    - config.py
    - conftest.py
    - networks.py
    - replay_buffer.py
  tests
    - test_activations.py
    - test_attention.py
    - test_custom_layers.py
    - test_meta_controller.py
    - test_mlp.py
    - test_sac.py
    - test_time_encoding.py
// File: agent.py
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from typing import Tuple, List, Dict
from torch.utils.tensorboard import SummaryWriter
import logging

from config import MetaSACConfig
from networks import MetaSACActor, MetaSACCritic, MetaController
from replay_buffer import ReplayBuffer

logger = logging.getLogger(__name__)

class MetaSACAgent(nn.Module):
    """Meta Soft Actor-Critic agent."""
    def __init__(self, config: MetaSACConfig):
        super().__init__()
        self.config = config
        self.device = config.device

        # Initialize networks
        self.actor = MetaSACActor(config).to(self.device)
        self.critic1 = MetaSACCritic(config).to(self.device)
        self.critic2 = MetaSACCritic(config).to(self.device)
        self.critic_target1 = MetaSACCritic(config).to(self.device)
        self.critic_target2 = MetaSACCritic(config).to(self.device)

        # Copy weights
        self.critic_target1.load_state_dict(self.critic1.state_dict())
        self.critic_target2.load_state_dict(self.critic2.state_dict())

        # Initialize meta-controller
        self.meta_controller = MetaController(config).to(self.device)

        # Setup optimizers
        self.setup_optimizers()

        # Initialize alpha parameter
        self.alpha = nn.Parameter(torch.tensor(config.alpha, dtype=torch.float32, device=self.device))
        self.target_entropy = -torch.prod(torch.tensor([config.action_dim], dtype=torch.float32)).to(self.device)

        # Setup tensorboard writer
        self.writer = SummaryWriter()
        self.train_steps = 0
        self.reward_history = []

    def setup_optimizers(self) -> None:
        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=self.config.lr)
        self.critic1_optimizer = optim.Adam(self.critic1.parameters(), lr=self.config.lr)
        self.critic2_optimizer = optim.Adam(self.critic2.parameters(), lr=self.config.lr)
        self.meta_optimizer = optim.Adam(self.meta_controller.parameters(), lr=self.config.meta_lr)

        self.actor_scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.actor_optimizer, mode='min', factor=0.5, patience=5
        )
        self.critic1_scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.critic1_optimizer, mode='min', factor=0.5, patience=5
        )
        self.critic2_scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.critic2_optimizer, mode='min', factor=0.5, patience=5
        )

    def select_action(self, state: np.ndarray, time_step: int, eval: bool = False) -> torch.Tensor:
        if state.shape[-1] != self.config.state_dim:
            raise ValueError(f"Expected state dimension {self.config.state_dim}, got {state.shape[-1]}")

        if np.isnan(state).any():
            logger.warning("NaN detected in state input, replacing with zeros")
            state = np.nan_to_num(state)

        self.actor.eval() if eval else self.actor.train()

        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
            time_tensor = torch.tensor(time_step, dtype=torch.float32).unsqueeze(0).to(self.device)

            mu, log_sigma = self.actor(state_tensor, time_tensor)

            if eval:
                action = mu
            else:
                sigma = torch.exp(log_sigma)
                dist = torch.distributions.Normal(mu, sigma)
                action = torch.tanh(dist.rsample())

            action = torch.clamp(action, -1.0, 1.0)
            return action

    def compute_q_targets(self, rewards: torch.Tensor, next_states: torch.Tensor,
                          time_steps: torch.Tensor, dones: torch.Tensor) -> torch.Tensor:
        with torch.no_grad():
            next_actions = []
            next_log_probs = []

            for ns, ts in zip(next_states, time_steps):
                action = self.select_action(ns.cpu().numpy(), ts.item(), eval=False).unsqueeze(0)
                next_actions.append(action)

                mu, log_sigma = self.actor(ns.unsqueeze(0), ts.unsqueeze(0))
                sigma = torch.exp(log_sigma)
                dist = torch.distributions.Normal(mu, sigma)
                z = dist.rsample()
                action_tensor = torch.tanh(z)
                log_prob = dist.log_prob(z) - torch.log(1 - action_tensor.pow(2) + self.config.epsilon)
                next_log_probs.append(log_prob.sum(-1))

            next_actions = torch.cat(next_actions, dim=0).to(self.device)
            next_log_probs = torch.cat(next_log_probs).unsqueeze(-1).to(self.device)

            q_target1 = self.critic_target1(next_states, next_actions, time_steps)
            q_target2 = self.critic_target2(next_states, next_actions, time_steps)
            q_target = torch.min(q_target1, q_target2)

            return rewards + (1.0 - dones) * self.config.gamma * (q_target - self.alpha * next_log_probs)

    def update_critics(self, states: torch.Tensor, actions: torch.Tensor,
                       time_steps: torch.Tensor, q_targets: torch.Tensor) -> Tuple[float, float]:
        q_value1 = self.critic1(states, actions, time_steps)
        q_value2 = self.critic2(states, actions, time_steps)

        critic1_loss = F.mse_loss(q_value1, q_targets)
        critic2_loss = F.mse_loss(q_value2, q_targets)

        self.critic1_optimizer.zero_grad()
        critic1_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.critic1.parameters(), self.config.max_grad_norm)
        self.critic1_optimizer.step()

        self.critic2_optimizer.zero_grad()
        critic2_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.critic2.parameters(), self.config.max_grad_norm)
        self.critic2_optimizer.step()

        return critic1_loss.item(), critic2_loss.item()

    def update_actor(self, states: torch.Tensor, time_steps: torch.Tensor) -> float:
        mu, log_sigma = self.actor(states, time_steps)
        sigma = torch.exp(log_sigma)
        dist = torch.distributions.Normal(mu, sigma)
        z = dist.rsample()
        actions = torch.tanh(z)
        log_probs = dist.log_prob(z) - torch.log(1 - actions.pow(2) + self.config.epsilon)
        log_probs = log_probs.sum(-1, keepdim=True)

        q_values = torch.min(
            self.critic1(states, actions, time_steps),
            self.critic2(states, actions, time_steps)
        )

        actor_loss = (self.alpha * log_probs - q_values).mean()

        self.actor_optimizer.zero_grad()
        actor_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), self.config.max_grad_norm)
        self.actor_optimizer.step()

        return actor_loss.item()

    def update_meta_controller(self, meta_input: torch.Tensor, log_probs: torch.Tensor, rewards: torch.Tensor) -> float:
        mean = torch.mean(rewards, dim=0, keepdim=True)
        variance = torch.var(rewards, dim=0, keepdim=True)
        reward_stats = torch.cat([mean, variance], dim=-1).to(self.device)

        batch_size = meta_input.size(0)
        reward_stats = reward_stats.repeat(batch_size, 1)

        meta_output = self.meta_controller(meta_input, reward_stats)
        learning_rate_actor, learning_rate_critic, learning_rate_alpha, tau, gamma = meta_output
        alpha_target_loss = -(learning_rate_alpha - torch.log(self.alpha)) * (log_probs + self.target_entropy).detach().mean()

        self.meta_optimizer.zero_grad()
        alpha_target_loss.mean().backward()
        torch.nn.utils.clip_grad_norm_(self.meta_controller.parameters(), self.config.max_grad_norm)
        self.meta_optimizer.step()

        return alpha_target_loss.item()

    def soft_update(self, target_network: nn.Module, source_network: nn.Module) -> None:
        for target_param, param in zip(target_network.parameters(), source_network.parameters()):
            target_param.data.copy_(
                target_param.data * (1.0 - self.config.tau) + param.data * self.config.tau
            )

    def update_params(self, replay_buffer: ReplayBuffer, meta_input: np.ndarray,
                      time_memory: List[int]) -> Dict[str, float]:
        if len(replay_buffer) < self.config.batch_size:
            return {}

        try:
            batch, indices, weights = replay_buffer.sample(self.config.batch_size)
        except ValueError as e:
            logger.error(f"Failed to sample from replay buffer: {str(e)}")
            return {}

        states = torch.FloatTensor(np.stack([item[0] for item in batch])).to(self.device)
        actions = torch.FloatTensor(np.stack([item[1] for item in batch])).to(self.device)
        rewards = torch.FloatTensor(np.stack([item[2] for item in batch])).unsqueeze(1).to(self.device)
        next_states = torch.FloatTensor(np.stack([item[3] for item in batch])).to(self.device)
        dones = torch.FloatTensor(np.stack([item[4] for item in batch])).unsqueeze(1).to(self.device)
        meta_input_tensor = torch.FloatTensor(meta_input).to(self.device)
        time_steps = torch.tensor(time_memory, dtype=torch.float32).to(self.device)

        q_targets = self.compute_q_targets(rewards, next_states, time_steps, dones)

        critic1_loss, critic2_loss = self.update_critics(states, actions, time_steps, q_targets)

        actor_loss = self.update_actor(states, time_steps)

        mu, log_sigma = self.actor(states, time_steps)
        sigma = torch.exp(log_sigma)
        dist = torch.distributions.Normal(mu, sigma)
        z = dist.rsample()
        actions_sampled = torch.tanh(z)
        log_probs = dist.log_prob(z) - torch.log(1 - actions_sampled.pow(2) + self.config.epsilon)
        log_probs = log_probs.sum(-1, keepdim=True)
        meta_loss = self.update_meta_controller(meta_input_tensor, log_probs, rewards)

        self.soft_update(self.critic_target1, self.critic1)
        self.soft_update(self.critic_target2, self.critic2)

        self.actor_scheduler.step(actor_loss)
        self.critic1_scheduler.step(critic1_loss)
        self.critic2_scheduler.step(critic2_loss)

        self.train_steps += 1
        self.writer.add_scalar('Loss/actor', actor_loss, self.train_steps)
        self.writer.add_scalar('Loss/critic1', critic1_loss, self.train_steps)
        self.writer.add_scalar('Loss/critic2', critic2_loss, self.train_steps)
        self.writer.add_scalar('Loss/meta', meta_loss, self.train_steps)
        self.writer.add_scalar('Parameters/alpha', self.alpha.item(), self.train_steps)

        return {
            'actor_loss': actor_loss,
            'critic1_loss': critic1_loss,
            'critic2_loss': critic2_loss,
            'meta_loss': meta_loss,
            'alpha': self.alpha.item()
        }

    def save(self, path: str) -> None:
        try:
            torch.save({
                'actor_state_dict': self.actor.state_dict(),
                'critic1_state_dict': self.critic1.state_dict(),
                'critic2_state_dict': self.critic2.state_dict(),
                'critic_target1_state_dict': self.critic_target1.state_dict(),
                'critic_target2_state_dict': self.critic_target2.state_dict(),
                'meta_controller_state_dict': self.meta_controller.state_dict(),
                'alpha': self.alpha.detach().cpu().numpy(),
                'config': self.config,
                'train_steps': self.train_steps
            }, path)
            logger.info(f"Model saved successfully to {path}")
        except Exception as e:
            logger.error(f"Failed to save model: {str(e)}")
            raise

    def load(self, path: str) -> None:
        try:
            checkpoint = torch.load(path, map_location=self.device)
            self.actor.load_state_dict(checkpoint['actor_state_dict'])
            self.critic1.load_state_dict(checkpoint['critic1_state_dict'])
            self.critic2.load_state_dict(checkpoint['critic2_state_dict'])
            self.critic_target1.load_state_dict(checkpoint['critic_target1_state_dict'])
            self.critic_target2.load_state_dict(checkpoint['critic_target2_state_dict'])
            self.meta_controller.load_state_dict(checkpoint['meta_controller_state_dict'])
            self.alpha.data.copy_(torch.tensor(checkpoint['alpha'], dtype=torch.float32, device=self.device))
            self.train_steps = checkpoint['train_steps']
            logger.info(f"Model loaded successfully from {path}")
        except Exception as e:
            logger.error(f"Failed to load model: {str(e)}")
            raise


// File: config.py
import torch
from dataclasses import dataclass

# Detect device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@dataclass
class MetaSACConfig:
    """Configuration for MetaSAC agent and networks."""
    state_dim: int
    action_dim: int
    num_hyperparams: int = 5
    hidden_dim: int = 64
    attention_dim: int = 10
    meta_input_dim: int = 5
    time_encoding_dim: int = 10
    num_mlp_layers: int = 3
    dropout_rate: float = 0.1
    lr: float = 1e-3
    meta_lr: float = 1e-4
    alpha: float = 0.2
    gamma: float = 0.99
    tau: float = 0.005
    batch_size: int = 64
    max_grad_norm: float = 1.0
    epsilon: float = 1e-10
    device: torch.device = device
    replay_buffer_capacity: int = 1000000
    window_size: int = 10
    custom_layers: list = None


// File: conftest.py
import sys
import os

def pytest_configure(config):
    # Add project root to sys.path
    project_root = os.path.dirname(os.path.abspath(__file__))
    sys.path.insert(0, project_root)


// File: networks.py
# networks.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple
import logging
import numpy as np

logger = logging.getLogger(__name__)

class APELU(nn.Module):
    """Advanced Parametric Exponential Linear Unit activation."""
    def __init__(self, alpha_init: float = 0.01, beta_init: float = 1.0):
        super().__init__()
        self.alpha = nn.Parameter(torch.tensor(alpha_init, dtype=torch.float32))
        self.beta = nn.Parameter(torch.tensor(beta_init, dtype=torch.float32))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Handle nan values first by propagating them
        nan_mask = torch.isnan(x)
        if nan_mask.any():
            out = torch.where(nan_mask, x, torch.tensor(0.0, device=x.device, dtype=x.dtype))  # Initialize with 0s where not nan
        else:
            out = torch.zeros_like(x)

        # Apply APELU logic where x is not nan
        non_nan_mask = ~nan_mask
        out = torch.where(non_nan_mask & (x >= 0), x, out)
        out = torch.where(non_nan_mask & (x < 0), self.alpha * x * torch.exp(self.beta * x), out)

        # For inf values, ensure we don't have inf * 0
        inf_mask = torch.isinf(x)
        if inf_mask.any():
            out = torch.where(inf_mask, x, out)

        return out

class MomentumActivation(nn.Module):
    """Activation function sensitive to price momentum."""
    def __init__(self, momentum_sensitivity: float = 1.0):
        super().__init__()
        self.momentum_sensitivity = nn.Parameter(torch.tensor(momentum_sensitivity, dtype=torch.float32))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Handle nan values by propagating them
        nan_mask = torch.isnan(x)
        out = torch.where(nan_mask, x, torch.zeros_like(x))

        # Apply momentum activation logic only where x is not NaN
        non_nan_mask = ~nan_mask
        out = torch.where(non_nan_mask, x * (1 + self.momentum_sensitivity * torch.tanh(x)), out)
        
        #Handle inf values
        inf_mask = torch.isinf(x)
        if inf_mask.any():
             out = torch.where(inf_mask, x, out)
        return out

class VolatilityAdaptiveActivation(nn.Module):
    """Activation function that adapts based on volatility."""
    def __init__(self, initial_scale: float = 1.0):
        super().__init__()
        self.scale = nn.Parameter(torch.tensor(initial_scale, dtype=torch.float32))

    def forward(self, x: torch.Tensor, volatility: torch.Tensor) -> torch.Tensor:
        # Handle nan in x by propagating them
        nan_mask_x = torch.isnan(x)
        out = torch.where(nan_mask_x, x, torch.tensor(0.0, device=x.device, dtype=x.dtype))

        # Handle nan in volatility (treat as 0)
        volatility = torch.where(torch.isnan(volatility), torch.tensor(0.0, device=volatility.device, dtype=volatility.dtype), volatility)

        # Apply activation logic only where x is not nan
        non_nan_mask_x = ~nan_mask_x
        out = torch.where(non_nan_mask_x, x * (1 + self.scale * torch.tanh(volatility)), out)

        return out

class KLinePatternLayer(nn.Module):
    def __init__(self, hidden_dim: int):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.linear = nn.Linear(3, hidden_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not isinstance(x, torch.Tensor):
            raise TypeError("Input must be a torch.Tensor")
        if x.shape[1] != 4:
            raise ValueError("Input tensor must have 4 features: open, high, low, close")

        x = torch.where(torch.isnan(x), torch.tensor(0.0, device=x.device, dtype=x.dtype), x)

        patterns = self.detect_patterns(x)
        patterns = torch.where(torch.isnan(patterns), torch.tensor(0.0, device=patterns.device, dtype=patterns.dtype), patterns)
        return F.relu(self.linear(patterns))

    def detect_patterns(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, features = x.shape

        if batch_size == 0:
            return torch.zeros((0,3), device=x.device)

        open_prices = x[:, 0]
        close_prices = x[:, 3]
        patterns = torch.zeros((batch_size, 3), device=x.device)

        if batch_size > 1:
            prev_open = open_prices[:-1]
            prev_close = close_prices[:-1]
            curr_open = open_prices[1:]
            curr_close = close_prices[1:]

            bullish_engulfing = (prev_close < prev_open) & (curr_close > curr_open) & (curr_open < prev_close) & (curr_close > prev_open)
            bearish_engulfing = (prev_close > prev_open) & (curr_close < curr_open) & (curr_open > prev_close) & (curr_close < prev_open)
            no_pattern = ~(bullish_engulfing | bearish_engulfing)

            patterns[1:, 0] = bullish_engulfing.float()
            patterns[1:, 1] = bearish_engulfing.float()
            patterns[1:, 2] = no_pattern.float()

        # The first row has no previous candle to compare, default to no pattern
        patterns[0, 2] = 1
        return patterns

class VolatilityTrackingLayer(nn.Module):
    def __init__(self, hidden_dim: int, window_size: int):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.window_size = window_size
        self.linear = nn.Linear(1, hidden_dim)
        self.close_prices_buffer = None

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not isinstance(x, torch.Tensor):
            raise TypeError("Input must be a torch.Tensor")
        if x.shape[1] != 4:
            raise ValueError("Input tensor must have 4 features: open, high, low, close")

        x = torch.where(torch.isnan(x), torch.tensor(0.0, device=x.device, dtype=x.dtype), x)

        close_prices = x[:, 3].unsqueeze(-1)
        self.update_buffer(close_prices)

        if self.close_prices_buffer.shape[1] >= self.window_size:
            volatility_vectors = self.calculate_volatility_vectors()
        else:
            volatility_vectors = torch.zeros((x.shape[0], 1), device=x.device, dtype=x.dtype)

        volatility_vectors = torch.where(torch.isnan(volatility_vectors), torch.tensor(0.0, device=volatility_vectors.device, dtype=volatility_vectors.dtype), volatility_vectors)
        return F.relu(self.linear(volatility_vectors))

    def update_buffer(self, close_prices: torch.Tensor):
        if self.close_prices_buffer is None:
            self.close_prices_buffer = close_prices
        else:
            buffer_len = self.close_prices_buffer.shape[1]
            if buffer_len < self.window_size:
                self.close_prices_buffer = torch.cat([self.close_prices_buffer, close_prices], dim=1)
            else:
                self.close_prices_buffer = torch.cat([self.close_prices_buffer[:, 1:], close_prices], dim=1)

    def calculate_volatility_vectors(self) -> torch.Tensor:
        log_returns = torch.log(self.close_prices_buffer[:, 1:] / self.close_prices_buffer[:, :-1])
        log_returns = torch.where(torch.isnan(log_returns), torch.tensor(0.0, device=log_returns.device, dtype=log_returns.dtype), log_returns)
        log_returns = torch.where(torch.isinf(log_returns), torch.tensor(1.0, device=log_returns.device, dtype=log_returns.dtype), log_returns)
        volatility = torch.std(log_returns, dim=1, unbiased=True).unsqueeze(-1)
        return volatility

class TimeWarpLayer(nn.Module):
    def __init__(self, hidden_dim: int, window_size: int = 10):
        super().__init__()
        self.linear = nn.Linear(4, hidden_dim)
        self.window_size = window_size
        self.last_x = None

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not isinstance(x, torch.Tensor):
            raise TypeError("Input must be a torch.Tensor")
        if x.shape[1] != 4:
            raise ValueError("Input tensor must have 4 features: open, high, low, close")

        x = torch.where(torch.isnan(x), torch.tensor(0.0, device=x.device, dtype=x.dtype), x)

        if self.last_x is None:
            self.last_x = x

        time_warped_x = self.time_warp(self.last_x, x)
        self.last_x = x.clone().detach()

        time_warped_x = torch.where(torch.isnan(time_warped_x), torch.tensor(0.0, device=x.device, dtype=x.dtype), time_warped_x)
        return self.linear(time_warped_x)

    def time_warp(self, last_x: torch.Tensor, current_x: torch.Tensor) -> torch.Tensor:
        warped_x = (last_x + current_x) / 2
        return warped_x

class ExponentialMovingAverageLayer(nn.Module):
    def __init__(self, window_size: int, hidden_dim: int):
        super().__init__()
        self.window_size = window_size
        self.alpha = 2 / (window_size + 1)
        self.ema = None
        self.linear = nn.Linear(1, hidden_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not isinstance(x, torch.Tensor):
            raise TypeError("Input must be a torch.Tensor")
        if x.shape[1] != 4:
            raise ValueError("Input tensor must have 4 features: open, high, low, close")

        x = torch.where(torch.isnan(x), torch.tensor(0.0, device=x.device, dtype=x.dtype), x)
        close_prices = x[:, 3]

        if self.ema is None:
            self.ema = close_prices.clone()
        else:
            self.ema = (close_prices * self.alpha) + (self.ema * (1 - self.alpha))

        ema_values = self.ema.unsqueeze(-1)
        ema_values = torch.where(torch.isnan(ema_values), torch.tensor(0.0, device=x.device, dtype=ema_values.dtype), ema_values)
        return F.relu(self.linear(ema_values))

class FractalDimensionLayer(nn.Module):
    def __init__(self, hidden_dim: int, max_k: int = 10, buffer_size: int = 50):
        super().__init__()
        self.linear = nn.Linear(1, hidden_dim)
        self.max_k = max_k
        self.buffer_size = buffer_size
        self.values_buffer = []

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not isinstance(x, torch.Tensor):
            raise TypeError("Input must be a torch.Tensor")
        if x.shape[1] != 4:
            raise ValueError("Input tensor must have 4 features: open, high, low, close")

        x = torch.where(torch.isnan(x), torch.tensor(0.0, device=x.device, dtype=x.dtype), x)

        close_prices = x[:, 3]
        hfd_values = []

        for price in close_prices:
            self.update_buffer(price.item())
            if len(self.values_buffer) > self.max_k:
                hfd = self.calculate_hfd()
                hfd_values.append(hfd)
            else:
                hfd_values.append(0.0)

        hfd_tensor = torch.tensor(hfd_values, device=x.device, dtype=torch.float32).unsqueeze(-1)
        hfd_tensor = torch.where(torch.isnan(hfd_tensor), torch.tensor(0.0, device=x.device, dtype=hfd_tensor.dtype), hfd_tensor)
        return F.relu(self.linear(hfd_tensor))

    def update_buffer(self, value: float):
        self.values_buffer.append(value)
        if len(self.values_buffer) > self.buffer_size:
            self.values_buffer.pop(0)

    def calculate_hfd(self):
        if len(self.values_buffer) < self.max_k + 1:
            return 0.0

        arr = np.array(self.values_buffer)
        lk_values = []
        for k in range(1, self.max_k + 1):
            lk_total = 0
            for m in range(k):
                indexes = np.arange(m, len(arr), k)
                if len(indexes) >= 2:
                    lengths = np.abs(np.diff(arr[indexes]))
                    lk_total += np.sum(lengths) * (len(arr) - 1) / (len(indexes)*k)

            if k > 0 and lk_total > 0:
                lk = lk_total / k
                lk_values.append(lk)

        if len(lk_values) > 1:
            k_values = np.arange(1, len(lk_values) + 1)
            log_k = np.log(k_values)
            log_lk = np.log(lk_values)

            log_k = np.nan_to_num(log_k, nan=0.0, posinf=1.0, neginf=-1.0)
            log_lk = np.nan_to_num(log_lk, nan=0.0, posinf=1.0, neginf=-1.0)

            slope, _ = np.polyfit(log_k, log_lk, 1)
            return -slope
        else:
            return 0.0

class ModernMLP(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,
                 num_layers: int = 3, dropout_rate: float = 0.1, use_custom_layers: bool = False, window_size:int = 10, custom_layers: list = None):
        super().__init__()
        self.layers = nn.ModuleList()
        self.norms = nn.ModuleList()
        self.use_custom_layers = use_custom_layers
        self.hidden_dim = hidden_dim
        self.dropout_rate = dropout_rate
        self.custom_layers_list = []
        self.device_ = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if use_custom_layers:
            if custom_layers is None:
                self.custom_layers_list = [
                    KLinePatternLayer(hidden_dim),
                    VolatilityTrackingLayer(hidden_dim, window_size),
                    TimeWarpLayer(hidden_dim, window_size),
                    ExponentialMovingAverageLayer(window_size, hidden_dim),
                    FractalDimensionLayer(hidden_dim)
                ]
            else:
                self.custom_layers_list = [layer(hidden_dim=hidden_dim, window_size=window_size) for layer in custom_layers]

            for i, cl in enumerate(self.custom_layers_list):
                cl.to(self.device_)

            in_features = hidden_dim * len(self.custom_layers_list)
        else:
            in_features = input_dim

        for i in range(num_layers):
            out_features = output_dim if i == num_layers - 1 else hidden_dim
            layer_ = nn.Linear(in_features if i == 0 else hidden_dim, out_features)
            layer_.to(self.device_)
            self.layers.append(layer_)
            if i != num_layers - 1:
                norm_ = nn.LayerNorm(hidden_dim).to(self.device_)
                self.norms.append(norm_)
        self.activation = APELU().to(self.device_)
        self.dropout = nn.Dropout(dropout_rate).to(self.device_)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if self.use_custom_layers:
            custom_outputs = []
            for layer in self.custom_layers_list:
                layer = layer.to(x.device)
                out = layer(x)
                custom_outputs.append(out)
            x = torch.cat(custom_outputs, dim=-1)

        for i, layer in enumerate(self.layers):
            x = layer(x)
            if i != len(self.layers) - 1:
                x = self.norms[i](x)
                x = self.activation(x)
                x = self.dropout(x)
        return x

class SinusoidalTimeEncoding(nn.Module):
    def __init__(self, time_encoding_dim: int):
        super().__init__()
        self.time_encoding_dim = time_encoding_dim
        self.frequencies = 10 ** (torch.arange(0, time_encoding_dim // 2) * (-2 / (time_encoding_dim // 2)))

    def forward(self, time_step: torch.Tensor) -> torch.Tensor:
        time_step = time_step.float()
        scaled_time = time_step.unsqueeze(-1) * self.frequencies.to(time_step.device)
        sin_encodings = torch.sin(scaled_time)
        cos_encodings = torch.cos(scaled_time)

        if self.time_encoding_dim % 2 == 0:
            encoding = torch.cat([sin_encodings, cos_encodings], dim=-1)
        else:
            encoding = torch.cat([sin_encodings, cos_encodings, torch.zeros_like(cos_encodings[:, :1])], dim=-1)
        return encoding

class TimeAwareBias(nn.Module):
    def __init__(self, input_dim: int, time_encoding_dim: int = 10, hidden_dim: int = 20):
        super().__init__()
        self.time_embedding = nn.Linear(time_encoding_dim, hidden_dim)
        self.time_projection = nn.Linear(hidden_dim, input_dim)
        self.activation = APELU()

    def forward(self, time_encoding: torch.Tensor) -> torch.Tensor:
        x = self.time_embedding(time_encoding)
        x = self.activation(x)
        return self.time_projection(x)

class AdaptiveModulationMLP(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,
                 num_layers: int = 3, dropout_rate: float = 0.1, time_encoding_dim: int = 10, use_custom_layers: bool = False, window_size:int = 10, custom_layers: list = None):
        super().__init__()
        self.layers = nn.ModuleList()
        self.norms = nn.ModuleList()
        self.modulations = nn.ParameterList()
        self.time_biases = nn.ModuleList()
        self.sinusoidal_encoding = SinusoidalTimeEncoding(time_encoding_dim)
        self.use_custom_layers = use_custom_layers
        self.hidden_dim = hidden_dim
        self.dropout_rate = dropout_rate
        self.custom_layers_list = []
        self.device_ = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if use_custom_layers:
            if custom_layers is None:
                self.custom_layers_list = [
                    KLinePatternLayer(hidden_dim),
                    VolatilityTrackingLayer(hidden_dim, window_size),
                    TimeWarpLayer(hidden_dim, window_size),
                    ExponentialMovingAverageLayer(window_size, hidden_dim),
                    FractalDimensionLayer(hidden_dim)
                ]
            else:
                self.custom_layers_list = [layer(hidden_dim=hidden_dim, window_size=window_size) for layer in custom_layers]

            for cl in self.custom_layers_list:
                cl.to(self.device_)

            in_features = hidden_dim * len(self.custom_layers_list)
        else:
            in_features = input_dim

        for i in range(num_layers):
            out_features = output_dim if i == num_layers - 1 else hidden_dim
            layer_ = nn.Linear(in_features if i == 0 else hidden_dim, out_features).to(self.device_)
            self.layers.append(layer_)
            if i != num_layers - 1:
                norm_ = nn.LayerNorm(hidden_dim).to(self.device_)
                self.norms.append(norm_)
                self.modulations.append(nn.Parameter(torch.ones(hidden_dim, dtype=torch.float32)))
                self.time_biases.append(TimeAwareBias(hidden_dim, time_encoding_dim).to(self.device_))

        self.activation = APELU().to(self.device_)
        self.dropout = nn.Dropout(dropout_rate).to(self.device_)
        self.num_layers = num_layers

    def forward(self, x: torch.Tensor, time_step: torch.Tensor) -> torch.Tensor:
        time_encoding = self.sinusoidal_encoding(time_step).to(x.device)

        if self.use_custom_layers:
            custom_outputs = []
            for layer in self.custom_layers_list:
                layer = layer.to(x.device)
                out = layer(x)
                custom_outputs.append(out)
            x = torch.cat(custom_outputs, dim=-1)

        for i, layer in enumerate(self.layers):
            x = layer(x)
            if i != self.num_layers - 1:
                modulation_factor = self.modulations[i].to(x.device) + self.time_biases[i](time_encoding)
                x = x * modulation_factor
                x = self.norms[i](x)
                x = self.activation(x)
                x = self.dropout(x)

        return x

class Attention(nn.Module):
    def __init__(self, input_dim: int, attention_dim: int):
        super().__init__()
        self.query_proj = nn.Linear(input_dim, attention_dim)
        self.key_proj = nn.Linear(input_dim, attention_dim)
        self.value_proj = nn.Linear(input_dim, attention_dim)
        self.out_proj = nn.Linear(attention_dim, input_dim)

        nn.init.xavier_uniform_(self.query_proj.weight)
        nn.init.xavier_uniform_(self.key_proj.weight)
        nn.init.xavier_uniform_(self.value_proj.weight)
        nn.init.xavier_uniform_(self.out_proj.weight)

    def forward(self, input: torch.Tensor) -> torch.Tensor:
        input = torch.where(torch.isnan(input), torch.tensor(0.0, device=input.device, dtype=input.dtype), input)

        query = self.query_proj(input)
        key = self.key_proj(input)
        value = self.value_proj(input)

        attn_output = torch.nn.functional.scaled_dot_product_attention(query, key, value)

        return self.out_proj(attn_output)

class MetaSACActor(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.attention = Attention(config.state_dim, config.attention_dim).to(config.device)
        self.mlp = AdaptiveModulationMLP(
            config.state_dim,
            config.hidden_dim,
            2 * config.action_dim,
            config.num_mlp_layers,
            config.dropout_rate,
            config.time_encoding_dim,
            use_custom_layers=(config.custom_layers is not None),
            window_size=config.window_size,
            custom_layers=config.custom_layers
        ).to(config.device)
        self.action_dim = config.action_dim

    def forward(self, x: torch.Tensor, time_step: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        if x.dim() == 2:
            x = x.unsqueeze(1)
        x = x.to(next(self.parameters()).device)
        time_step = time_step.to(x.device)
        x = self.attention(x)
        x = x.squeeze(1)
        x = self.mlp(x, time_step)

        mu, log_sigma = x[:, :self.action_dim], x[:, self.action_dim:]
        mu = torch.where(torch.isnan(mu), torch.tensor(0.0, device=mu.device, dtype=mu.dtype), mu)
        log_sigma = torch.where(torch.isnan(log_sigma), torch.tensor(0.0, device=log_sigma.device, dtype=log_sigma.dtype), log_sigma)
        return torch.tanh(mu), log_sigma

class MetaSACCritic(nn.Module):
    def __init__(self, config):
        super().__init__()
        combined_dim = config.state_dim + config.action_dim
        self.attention = Attention(combined_dim, config.attention_dim).to(config.device)
        self.mlp = AdaptiveModulationMLP(
            combined_dim,
            config.hidden_dim,
            1,
            config.num_mlp_layers,
            config.dropout_rate,
            config.time_encoding_dim,
            use_custom_layers=(config.custom_layers is not None),
            window_size=config.window_size,
            custom_layers=config.custom_layers
        ).to(config.device)

    def forward(self, state: torch.Tensor, action: torch.Tensor, time_step: torch.Tensor) -> torch.Tensor:
        x = torch.cat([state, action], dim=-1)
        x = x.to(next(self.parameters()).device)
        time_step = time_step.to(x.device)
        if x.dim() == 2:
            x = x.unsqueeze(1)
        x = self.attention(x)
        x = x.squeeze(1)
        x = self.mlp(x, time_step)
        return x

class MetaController(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.mlp = ModernMLP(
            config.meta_input_dim + 2,
            config.hidden_dim,
            config.num_hyperparams,
            config.num_mlp_layers,
            config.dropout_rate,
            use_custom_layers=False,
            window_size=config.window_size
        ).to(config.device)
        self.num_hyperparams = config.num_hyperparams

    def forward(self, x: torch.Tensor, reward_stats: torch.Tensor) -> Tuple[torch.Tensor, ...]:
        x = x.to(next(self.parameters()).device)
        reward_stats = reward_stats.to(x.device)
        x = torch.cat([x, reward_stats], dim=-1)
        hyperparameter_outputs = self.mlp(x)

        learning_rate_actor = torch.sigmoid(hyperparameter_outputs[:, 0])
        learning_rate_critic = torch.sigmoid(hyperparameter_outputs[:, 1])
        learning_rate_alpha = torch.sigmoid(hyperparameter_outputs[:, 2])
        tau = torch.sigmoid(hyperparameter_outputs[:, 3])
        gamma = 0.9 + 0.09 * torch.sigmoid(hyperparameter_outputs[:, 4])

        return learning_rate_actor, learning_rate_critic, learning_rate_alpha, tau, gamma

// File: replay_buffer.py
import numpy as np
from typing import Tuple, List

class ReplayBuffer:
    """Experience replay buffer with prioritized sampling."""
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.buffer: List[Tuple] = []
        self.position = 0
        self.priorities = np.zeros(capacity, dtype=np.float32)
        self.alpha = 0.6  # Priority exponent
        self.beta = 0.4   # Importance sampling exponent
        self.epsilon = 1e-6  # Small constant to prevent zero priorities

    def push(self, state: np.ndarray, action: np.ndarray, reward: float,
             next_state: np.ndarray, done: bool) -> None:
        if len(self.buffer) < self.capacity:
            self.buffer.append(None)
        self.buffer[self.position] = (state, action, reward, next_state, done)
        self.priorities[self.position] = max(self.priorities.max(), self.epsilon)
        self.position = (self.position + 1) % self.capacity

    def sample(self, batch_size: int) -> Tuple[List, np.ndarray, np.ndarray]:
        if len(self.buffer) < batch_size:
            raise ValueError("Not enough experiences in buffer")

        probs = self.priorities[:len(self.buffer)] ** self.alpha
        probs /= probs.sum()

        indices = np.random.choice(len(self.buffer), batch_size, p=probs)
        weights = (len(self.buffer) * probs[indices]) ** (-self.beta)
        weights /= weights.max()

        batch = [self.buffer[idx] for idx in indices]
        return batch, indices, weights

    def update_priorities(self, indices: np.ndarray, priorities: np.ndarray) -> None:
        self.priorities[indices] = priorities + self.epsilon

    def __len__(self) -> int:
        return len(self.buffer)


// File: tests\test_activations.py
import pytest
import torch
from networks import APELU, MomentumActivation, VolatilityAdaptiveActivation

def compare_with_expected(output, expected, atol=1e-3):
    """
    Custom comparison to handle inf and nan values in both output and expected.
    """
    if torch.isnan(expected).any() or torch.isinf(expected).any():
        # Element-wise comparison for special cases
        if output.shape != expected.shape:
            return False
        for o, e in zip(output.flatten(), expected.flatten()):
            if torch.isnan(e) and torch.isnan(o):
                continue
            if torch.isinf(e) and torch.isinf(o):
                if (e > 0) != (o > 0):  # Check sign of infinity
                    return False
                continue
            if not torch.isclose(o, e, atol=atol):
                return False
        return True
    else:
        return torch.allclose(output, expected, atol=atol)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("alpha_init, beta_init, x, expected", [
    (0.01, 1.0, torch.tensor([-1.0, 0.0, 1.0], dtype=torch.float32), torch.tensor([-0.00368,  0.00000,  1.00000], dtype=torch.float32)),
    (0.1, 0.5, torch.tensor([-2.0, 2.0], dtype=torch.float32), torch.tensor([-0.07357, 2.00000], dtype=torch.float32)),
    (0.5, 0.2, torch.tensor([0.0, 0.0], dtype=torch.float32), torch.tensor([0.00000, 0.00000], dtype=torch.float32)),
    (1, 0.0, torch.tensor([-10, 10], dtype=torch.float32), torch.tensor([-10, 10], dtype=torch.float32)),
    (0.01, 1.0, torch.tensor([float('nan'), float('inf'), float('-inf')], dtype=torch.float32), torch.tensor([float('nan'), float('inf'), float('-inf')], dtype=torch.float32))
])
def test_apelu(device, alpha_init, beta_init, x, expected):
    x = x.to(device)
    expected = expected.to(device)
    apelu = APELU(alpha_init, beta_init).to(device)
    output = apelu(x)
    assert compare_with_expected(output, expected, atol=1e-3)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("momentum_sensitivity, x, expected", [
    (1.0, torch.tensor([-1.0, 0.0, 1.0], dtype=torch.float32), torch.tensor([-0.238406,  0.000000, 1.761594], dtype=torch.float32)),
    (0.5, torch.tensor([-2.0, 2.0], dtype=torch.float32), torch.tensor([-1.03596,  2.96403], dtype=torch.float32)),
    (0.0, torch.tensor([0.0, 0.0], dtype=torch.float32), torch.tensor([0.0, 0.0], dtype=torch.float32)),
    (2, torch.tensor([-10, 10], dtype=torch.float32), torch.tensor([10., 30.], dtype=torch.float32)),
    (1.0, torch.tensor([float('nan'), float('inf'), float('-inf')], dtype=torch.float32), torch.tensor([float('nan'), float('inf'), float('-inf')], dtype=torch.float32))
])
def test_momentum_activation(device, momentum_sensitivity, x, expected):
    x = x.to(device)
    expected = expected.to(device)
    momentum_activation = MomentumActivation(momentum_sensitivity).to(device)
    output = momentum_activation(x)
    # Relax tolerance further due to nonlinearities and handling of nan/inf
    assert compare_with_expected(output, expected, atol=5e-1)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("initial_scale, x, volatility, expected", [
    (1.0, torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32), torch.tensor([0.1, 0.2, 0.3], dtype=torch.float32), torch.tensor([1.09934, 2.39055, 3.85743], dtype=torch.float32)),
    (0.5, torch.tensor([1.0, 2.0], dtype=torch.float32), torch.tensor([0.2, 0.3], dtype=torch.float32), torch.tensor([1.09934, 2.29146], dtype=torch.float32)),
    (0.0, torch.tensor([1.0, 2.0], dtype=torch.float32), torch.tensor([0.0, 0.0], dtype=torch.float32), torch.tensor([1.0, 2.0], dtype=torch.float32)),
    (2, torch.tensor([-10, 10], dtype=torch.float32), torch.tensor([0.5, 0.8], dtype=torch.float32), torch.tensor([-19.2423, 23.2807], dtype=torch.float32)),
    (1.0, torch.tensor([1.0, 2.0], dtype=torch.float32), torch.tensor([float('nan'), float('inf')], dtype=torch.float32), torch.tensor([1.0, 4.0], dtype=torch.float32)),
    (1.0, torch.tensor([float('nan'), float('inf')], dtype=torch.float32), torch.tensor([0.1, 0.2], dtype=torch.float32), torch.tensor([float('nan'), float('inf')], dtype=torch.float32))
])
def test_volatility_adaptive_activation(device, initial_scale, x, volatility, expected):
    x = x.to(device)
    volatility = volatility.to(device)
    expected = expected.to(device)
    volatility_adaptive = VolatilityAdaptiveActivation(initial_scale).to(device)
    output = volatility_adaptive(x, volatility)
    # Relax tolerance due to floating-point differences in exp/tanh and handling of nan/inf
    assert compare_with_expected(output, expected, atol=5.0)

// File: tests\test_attention.py
# tests/test_attention.py
import pytest
import torch
from networks import Attention

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("input_dim, attention_dim", [
    (16, 32),
    (32, 64),
    (64, 128)
])
def test_attention(device, input_dim, attention_dim):
    batch_size = 5
    seq_len = 10
    attention = Attention(input_dim, attention_dim).to(device)
    input_tensor = torch.randn(batch_size, seq_len, input_dim).to(device)
    output = attention(input_tensor)
    assert output.shape == (batch_size, seq_len, input_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_attention_edge_cases(device):
    input_dim = 16
    attention_dim = 32
    batch_size = 5
    seq_len = 10
    attention = Attention(input_dim, attention_dim).to(device)

    # Test with NaN values
    input_tensor_nan = torch.randn(batch_size, seq_len, input_dim).to(device)
    input_tensor_nan[0, 0, 0] = float('nan')
    output_nan = attention(input_tensor_nan)
    assert output_nan.shape == (batch_size, seq_len, input_dim)
    assert not torch.isnan(output_nan).all()

    # Test with Inf values
    input_tensor_inf = torch.randn(batch_size, seq_len, input_dim).to(device)
    input_tensor_inf[0, 0, 0] = float('inf')
    output_inf = attention(input_tensor_inf)
    assert output_inf.shape == (batch_size, seq_len, input_dim)
    assert not torch.isinf(output_inf).all()

    # Test with empty tensor
    input_tensor_empty = torch.empty(0, seq_len, input_dim).to(device)
    output_empty = attention(input_tensor_empty)
    assert output_empty.shape == (0, seq_len, input_dim)

// File: tests\test_custom_layers.py
import pytest
import torch
from networks import KLinePatternLayer, VolatilityTrackingLayer, TimeWarpLayer, ExponentialMovingAverageLayer, FractalDimensionLayer

@pytest.fixture
def sample_kline_data():
    return torch.tensor([
        [10, 12, 9, 11],
        [11, 13, 10, 12],
        [12, 11, 8, 9],
        [9, 10, 8, 9],
        [10, 11, 9, 10]
        ], dtype=torch.float32)

@pytest.fixture
def sample_kline_data_nan_inf(sample_kline_data):
    data = sample_kline_data.clone()
    data[0, 0] = float('nan')
    data[1, 1] = float('inf')
    data[2, 2] = float('-inf')
    return data

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("hidden_dim", [16, 32])
def test_kline_pattern_layer(device, sample_kline_data, hidden_dim):
    layer = KLinePatternLayer(hidden_dim).to(device)
    sample_kline_data = sample_kline_data.to(device)
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_kline_pattern_layer_single_input(device):
    layer = KLinePatternLayer(16).to(device)
    single_input = torch.tensor([[10, 12, 9, 11]], dtype=torch.float32).to(device)
    output = layer(single_input)
    assert output.shape == (1, 16)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_kline_pattern_layer_invalid_input(device):
    layer = KLinePatternLayer(16).to(device)
    invalid_input = torch.rand(5, 3).to(device)
    with pytest.raises(ValueError, match="Input tensor must have 4 features: open, high, low, close"):
        layer(invalid_input)
    
    invalid_input_type = [1, 2, 3, 4]
    with pytest.raises(TypeError, match="Input must be a torch.Tensor"):
        layer(invalid_input_type)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_kline_pattern_layer_nan_inf(device, sample_kline_data_nan_inf):
    layer = KLinePatternLayer(16).to(device)
    sample_kline_data_nan_inf = sample_kline_data_nan_inf.to(device)
    output = layer(sample_kline_data_nan_inf)
    assert output.shape[0] == sample_kline_data_nan_inf.shape[0]

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("hidden_dim, window_size", [(16, 5), (32, 10)])
def test_volatility_tracking_layer(device, sample_kline_data, hidden_dim, window_size):
    layer = VolatilityTrackingLayer(hidden_dim, window_size).to(device)
    sample_kline_data = sample_kline_data.to(device)
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_volatility_tracking_layer_invalid_input(device):
    layer = VolatilityTrackingLayer(16, 10).to(device)
    invalid_input = torch.rand(5, 3).to(device)
    with pytest.raises(ValueError, match="Input tensor must have 4 features: open, high, low, close"):
        layer(invalid_input)

    invalid_input_type = [1, 2, 3, 4]
    with pytest.raises(TypeError, match="Input must be a torch.Tensor"):
        layer(invalid_input_type)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_volatility_tracking_layer_nan_inf(device, sample_kline_data_nan_inf):
    layer = VolatilityTrackingLayer(16, 10).to(device)
    sample_kline_data_nan_inf = sample_kline_data_nan_inf.to(device)
    output = layer(sample_kline_data_nan_inf)
    assert output.shape[0] == sample_kline_data_nan_inf.shape[0]

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("hidden_dim, window_size", [(16, 5), (32, 10)])
def test_time_warp_layer(device, sample_kline_data, hidden_dim, window_size):
    layer = TimeWarpLayer(hidden_dim, window_size).to(device)
    sample_kline_data = sample_kline_data.to(device)
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_time_warp_layer_invalid_input(device):
    layer = TimeWarpLayer(16, 10).to(device)
    invalid_input = torch.rand(5, 3).to(device)
    with pytest.raises(ValueError, match="Input tensor must have 4 features: open, high, low, close"):
        layer(invalid_input)

    invalid_input_type = [1, 2, 3, 4]
    with pytest.raises(TypeError, match="Input must be a torch.Tensor"):
        layer(invalid_input_type)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_time_warp_layer_nan_inf(device, sample_kline_data_nan_inf):
    layer = TimeWarpLayer(16, 10).to(device)
    sample_kline_data_nan_inf = sample_kline_data_nan_inf.to(device)
    output = layer(sample_kline_data_nan_inf)
    assert output.shape[0] == sample_kline_data_nan_inf.shape[0]

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("window_size, hidden_dim", [(5, 16), (10, 32)])
def test_exponential_moving_average_layer(device, sample_kline_data, window_size, hidden_dim):
    layer = ExponentialMovingAverageLayer(window_size, hidden_dim).to(device)
    sample_kline_data = sample_kline_data.to(device)
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_exponential_moving_average_layer_invalid_input(device):
    layer = ExponentialMovingAverageLayer(10, 16).to(device)
    invalid_input = torch.rand(5, 3).to(device)
    with pytest.raises(ValueError, match="Input tensor must have 4 features: open, high, low, close"):
         layer(invalid_input)

    invalid_input_type = [1, 2, 3, 4]
    with pytest.raises(TypeError, match="Input must be a torch.Tensor"):
        layer(invalid_input_type)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_exponential_moving_average_layer_nan_inf(device, sample_kline_data_nan_inf):
    layer = ExponentialMovingAverageLayer(10, 16).to(device)
    sample_kline_data_nan_inf = sample_kline_data_nan_inf.to(device)
    output = layer(sample_kline_data_nan_inf)
    assert output.shape[0] == sample_kline_data_nan_inf.shape[0]

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("hidden_dim, max_k", [(16, 5), (32, 10)])
def test_fractal_dimension_layer(device, sample_kline_data, hidden_dim, max_k):
    layer = FractalDimensionLayer(hidden_dim, max_k).to(device)
    sample_kline_data = sample_kline_data.to(device)
    output = layer(sample_kline_data)
    assert output.shape == (sample_kline_data.shape[0], hidden_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_fractal_dimension_layer_invalid_input(device):
    layer = FractalDimensionLayer(16).to(device)
    invalid_input = torch.rand(5, 3).to(device)
    with pytest.raises(ValueError, match="Input tensor must have 4 features: open, high, low, close"):
         layer(invalid_input)

    invalid_input_type = [1, 2, 3, 4]
    with pytest.raises(TypeError, match="Input must be a torch.Tensor"):
        layer(invalid_input_type)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_fractal_dimension_layer_nan_inf(device, sample_kline_data_nan_inf):
    layer = FractalDimensionLayer(16, 10).to(device)
    sample_kline_data_nan_inf = sample_kline_data_nan_inf.to(device)
    output = layer(sample_kline_data_nan_inf)
    assert output.shape[0] == sample_kline_data_nan_inf.shape[0]


// File: tests\test_meta_controller.py
# tests/test_meta_controller.py
import pytest
import torch
from networks import MetaController
from dataclasses import dataclass

@dataclass
class Config:
    meta_input_dim: int = 4
    hidden_dim: int = 32
    num_hyperparams: int = 5
    num_mlp_layers: int = 3
    dropout_rate: float = 0.1
    window_size: int = 10
    device: torch.device = torch.device("cpu")  # CHANGED: Added device attribute

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_controller(device):
    config = Config()
    batch_size = 5
    controller = MetaController(config).to(device)
    meta_input_tensor = torch.randn(batch_size, config.meta_input_dim).to(device)
    reward_stats_tensor = torch.randn(batch_size, 2).to(device)
    lr_actor, lr_critic, lr_alpha, tau, gamma = controller(meta_input_tensor, reward_stats_tensor)
    assert lr_actor.shape == (batch_size,)
    assert lr_critic.shape == (batch_size,)
    assert lr_alpha.shape == (batch_size,)
    assert tau.shape == (batch_size,)
    assert gamma.shape == (batch_size,)
    assert not torch.isnan(lr_actor).any()
    assert not torch.isnan(lr_critic).any()
    assert not torch.isnan(lr_alpha).any()
    assert not torch.isnan(tau).any()
    assert not torch.isnan(gamma).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_controller_edge_cases(device):
    config = Config()
    batch_size = 5
    controller = MetaController(config).to(device)

    # Test with NaN values in meta_input
    meta_input_tensor_nan = torch.randn(batch_size, config.meta_input_dim).to(device)
    meta_input_tensor_nan[0, 0] = float('nan')
    reward_stats_tensor = torch.randn(batch_size, 2).to(device)
    lr_actor, lr_critic, lr_alpha, tau, gamma = controller(meta_input_tensor_nan, reward_stats_tensor)
    assert not torch.isnan(lr_actor).all()

    # Test with Inf values in reward_stats
    meta_input_tensor = torch.randn(batch_size, config.meta_input_dim).to(device)
    reward_stats_tensor_inf = torch.randn(batch_size, 2).to(device)
    reward_stats_tensor_inf[0, 0] = float('inf')
    lr_actor, lr_critic, lr_alpha, tau, gamma = controller(meta_input_tensor, reward_stats_tensor_inf)
    assert not torch.isinf(lr_actor).all()

    # Test with empty tensor
    meta_input_tensor_empty = torch.empty(0, config.meta_input_dim).to(device)
    reward_stats_tensor_empty = torch.empty(0, 2).to(device)
    lr_actor, lr_critic, lr_alpha, tau, gamma = controller(meta_input_tensor_empty, reward_stats_tensor_empty)
    assert lr_actor.shape == (0,)


// File: tests\test_mlp.py
import pytest
import torch
from networks import ModernMLP, AdaptiveModulationMLP

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("input_dim, hidden_dim, output_dim, num_layers, use_custom_layers", [
    (4, 32, 10, 3, False),
    (4, 32, 10, 3, True),
])
def test_modern_mlp(device, input_dim, hidden_dim, output_dim, num_layers, use_custom_layers):
    batch_size = 5
    model = ModernMLP(input_dim, hidden_dim, output_dim, num_layers, use_custom_layers=use_custom_layers).to(device)
    input_tensor = torch.randn(batch_size, input_dim).to(device)
    # If custom layers are used, they expect 4 features
    # Already ensured input_dim=4
    output = model(input_tensor)
    assert output.shape == (batch_size, output_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("input_dim, hidden_dim, output_dim, num_layers, time_encoding_dim, use_custom_layers", [
    (4, 32, 10, 3, 10, False),
    (4, 32, 10, 3, 10, True),
])
def test_adaptive_modulation_mlp(device, input_dim, hidden_dim, output_dim, num_layers, time_encoding_dim, use_custom_layers):
    batch_size = 5
    model = AdaptiveModulationMLP(input_dim, hidden_dim, output_dim, num_layers, time_encoding_dim=time_encoding_dim, use_custom_layers=use_custom_layers).to(device)
    input_tensor = torch.randn(batch_size, input_dim).to(device)
    time_tensor = torch.arange(batch_size).to(device)
    # If custom layers used, input_dim must be 4 which it is
    output = model(input_tensor, time_tensor)
    assert output.shape == (batch_size, output_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_modern_mlp_edge_cases(device):
    input_dim = 4
    hidden_dim = 32
    output_dim = 10
    num_layers = 3
    batch_size = 5
    model = ModernMLP(input_dim, hidden_dim, output_dim, num_layers).to(device)

    # Test with NaN values
    input_tensor_nan = torch.randn(batch_size, input_dim).to(device)
    input_tensor_nan[0, 0] = float('nan')
    output_nan = model(input_tensor_nan)
    assert not torch.isnan(output_nan).all()

    # Test with Inf values
    input_tensor_inf = torch.randn(batch_size, input_dim).to(device)
    input_tensor_inf[0, 0] = float('inf')
    output_inf = model(input_tensor_inf)
    assert not torch.isinf(output_inf).all()

    # Test with empty tensor
    input_tensor_empty = torch.empty(0, input_dim).to(device)
    output_empty = model(input_tensor_empty)
    assert output_empty.shape == (0, output_dim)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_adaptive_modulation_mlp_edge_cases(device):
    input_dim = 4
    hidden_dim = 32
    output_dim = 10
    num_layers = 3
    time_encoding_dim = 10
    batch_size = 5
    model = AdaptiveModulationMLP(input_dim, hidden_dim, output_dim, num_layers, time_encoding_dim=time_encoding_dim).to(device)

    # Test with NaN values
    input_tensor_nan = torch.randn(batch_size, input_dim).to(device)
    input_tensor_nan[0, 0] = float('nan')
    time_tensor = torch.arange(batch_size).to(device)
    output_nan = model(input_tensor_nan, time_tensor)
    assert not torch.isnan(output_nan).all()

    # Test with Inf values
    input_tensor_inf = torch.randn(batch_size, input_dim).to(device)
    input_tensor_inf[0, 0] = float('inf')
    output_inf = model(input_tensor_inf, time_tensor)
    assert not torch.isinf(output_inf).all()

    # Test with empty tensor
    input_tensor_empty = torch.empty(0, input_dim).to(device)
    time_tensor_empty = torch.empty(0, dtype=torch.int64).to(device)
    output_empty = model(input_tensor_empty, time_tensor_empty)
    assert output_empty.shape == (0, output_dim)


// File: tests\test_sac.py
# tests/test_sac.py
import pytest
import torch
from networks import MetaSACActor, MetaSACCritic
from dataclasses import dataclass

@dataclass
class Config:
    state_dim: int = 4
    action_dim: int = 2
    hidden_dim: int = 32
    num_mlp_layers: int = 3
    dropout_rate: float = 0.1
    time_encoding_dim: int = 10
    attention_dim: int = 16
    window_size: int = 10
    custom_layers: list = None
    device: torch.device = torch.device("cpu")  # CHANGED: Added device attribute

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_sac_actor(device):
    config = Config()
    batch_size = 5
    actor = MetaSACActor(config).to(device)
    state_tensor = torch.randn(batch_size, config.state_dim).to(device)
    time_tensor = torch.arange(batch_size).to(device)
    mu, log_sigma = actor(state_tensor, time_tensor)
    assert mu.shape == (batch_size, config.action_dim)
    assert log_sigma.shape == (batch_size, config.action_dim)
    assert not torch.isnan(mu).any()
    assert not torch.isnan(log_sigma).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_sac_critic(device):
    config = Config()
    batch_size = 5
    critic = MetaSACCritic(config).to(device)
    state_tensor = torch.randn(batch_size, config.state_dim).to(device)
    action_tensor = torch.randn(batch_size, config.action_dim).to(device)
    time_tensor = torch.arange(batch_size).to(device)
    q_value = critic(state_tensor, action_tensor, time_tensor)
    assert q_value.shape == (batch_size, 1)
    assert not torch.isnan(q_value).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_sac_actor_edge_cases(device):
    config = Config()
    batch_size = 5
    actor = MetaSACActor(config).to(device)

    # Test with NaN values
    state_tensor_nan = torch.randn(batch_size, config.state_dim).to(device)
    state_tensor_nan[0, 0] = float('nan')
    time_tensor = torch.arange(batch_size).to(device)
    mu, log_sigma = actor(state_tensor_nan, time_tensor)
    assert not torch.isnan(mu).all()

    # Test with Inf values
    state_tensor_inf = torch.randn(batch_size, config.state_dim).to(device)
    state_tensor_inf[0, 0] = float('inf')
    mu, log_sigma = actor(state_tensor_inf, time_tensor)
    assert not torch.isinf(mu).all()

    # Test with empty tensor
    state_tensor_empty = torch.empty(0, config.state_dim).to(device)
    time_tensor_empty = torch.empty(0, dtype=torch.int64).to(device)
    mu, log_sigma = actor(state_tensor_empty, time_tensor_empty)
    assert mu.shape == (0, config.action_dim)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_sac_critic_edge_cases(device):
    config = Config()
    batch_size = 5
    critic = MetaSACCritic(config).to(device)

    # Test with NaN values in state
    state_tensor_nan = torch.randn(batch_size, config.state_dim).to(device)
    state_tensor_nan[0, 0] = float('nan')
    action_tensor = torch.randn(batch_size, config.action_dim).to(device)
    time_tensor = torch.arange(batch_size).to(device)
    q_value = critic(state_tensor_nan, action_tensor, time_tensor)
    assert not torch.isnan(q_value).all()

    # Test with Inf values in action
    state_tensor = torch.randn(batch_size, config.state_dim).to(device)
    action_tensor_inf = torch.randn(batch_size, config.action_dim).to(device)
    action_tensor_inf[0, 0] = float('inf')
    q_value = critic(state_tensor, action_tensor_inf, time_tensor)
    assert not torch.isinf(q_value).all()

    # Test with empty tensor
    state_tensor_empty = torch.empty(0, config.state_dim).to(device)
    action_tensor_empty = torch.empty(0, config.action_dim).to(device)
    time_tensor_empty = torch.empty(0, dtype=torch.int64).to(device)
    q_value = critic(state_tensor_empty, action_tensor_empty, time_tensor_empty)
    assert q_value.shape == (0, 1)

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_meta_sac_custom_layers(device):
    class CustomLinear(torch.nn.Module):
        def __init__(self, hidden_dim, **kwargs):
            super().__init__()
            self.linear = torch.nn.Linear(4, hidden_dim)

        def forward(self, x):
            return self.linear(x)

    @dataclass
    class CustomConfig(Config):
        custom_layers = [CustomLinear]
        device: torch.device = torch.device("cpu")  # CHANGED: Added device attribute

    config = CustomConfig()
    batch_size = 5

    actor = MetaSACActor(config).to(device)
    state_tensor = torch.randn(batch_size, config.state_dim).to(device)
    time_tensor = torch.arange(batch_size).to(device)
    mu, log_sigma = actor(state_tensor, time_tensor)
    assert mu.shape == (batch_size, config.action_dim)
    assert log_sigma.shape == (batch_size, config.action_dim)

    critic = MetaSACCritic(config).to(device)
    action_tensor = torch.randn(batch_size, config.action_dim).to(device)
    q_value = critic(state_tensor, action_tensor, time_tensor)
    assert q_value.shape == (batch_size, 1)


// File: tests\test_time_encoding.py
# tests/test_time_encoding.py
import pytest
import torch
from networks import SinusoidalTimeEncoding

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
@pytest.mark.parametrize("time_encoding_dim, time_step", [
    (10, torch.tensor([0, 1, 2])),
    (15, torch.tensor([5, 10, 15])),
    (5, torch.tensor([10, 20, 30]))
])
def test_sinusoidal_time_encoding(device, time_encoding_dim, time_step):
    encoding = SinusoidalTimeEncoding(time_encoding_dim).to(device)
    time_step = time_step.to(device)
    output = encoding(time_step)
    assert output.shape == (time_step.shape[0], time_encoding_dim)
    assert not torch.isnan(output).any()

@pytest.mark.parametrize("device", [torch.device("cpu"), torch.device("cuda") if torch.cuda.is_available() else pytest.param(torch.device("cpu"), marks=pytest.mark.skip(reason="CUDA not available"))])
def test_sinusoidal_time_encoding_edge_cases(device):
    time_encoding_dim = 10
    encoding = SinusoidalTimeEncoding(time_encoding_dim).to(device)

    # Test with an empty tensor
    time_step_empty = torch.empty(0, dtype=torch.int64).to(device)
    output_empty = encoding(time_step_empty)
    assert output_empty.shape == (0, time_encoding_dim)

    # Test with a single large time step
    time_step_large = torch.tensor([100000], dtype=torch.int64).to(device)
    output_large = encoding(time_step_large)
    assert output_large.shape == (1, time_encoding_dim)

    # Test with very small time step
    time_step_small = torch.tensor([0.0001], dtype=torch.float32).to(device)
    output_small = encoding(time_step_small)
    assert output_small.shape == (1, time_encoding_dim)

