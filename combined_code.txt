// File: agent.py
# File: agent.py
import torch
import torch.nn as nn
from torch.optim import Adam
from torch.distributions import Normal
import numpy as np

class ActorCritic(nn.Module):
    def __init__(self, state_size, action_size, hidden_size=64):
        super(ActorCritic, self).__init__()
        # Common feature extraction
        self.feature = nn.Sequential(
            nn.Linear(state_size, hidden_size),
            nn.ReLU(),
        )
        # Actor network
        self.actor_mean = nn.Linear(hidden_size, action_size)
        self.actor_log_std = nn.Parameter(torch.zeros(action_size))
        # Critic network
        self.critic = nn.Linear(hidden_size, 1)

    def forward(self, state):
        feature = self.feature(state)
        mean = self.actor_mean(feature)
        std = self.actor_log_std.exp()
        value = self.critic(feature)
        return mean, std, value

class PPOAgent:
    def __init__(self, state_size, action_size, lr=1e-4, gamma=0.99, eps_clip=0.2, c1=0.5, c2=0.01):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = ActorCritic(state_size, action_size).to(self.device)
        self.optimizer = Adam(self.model.parameters(), lr=lr)
        self.gamma = gamma
        self.eps_clip = eps_clip
        self.c1 = c1  # Critic loss coefficient
        self.c2 = c2  # Entropy coefficient

    def select_action(self, state):
        state = torch.FloatTensor(state).to(self.device)
        with torch.no_grad():
            mean, std, _ = self.model(state)
        dist = Normal(mean, std)
        action = dist.rsample()
        tanh_action = torch.tanh(action)
        log_prob = dist.log_prob(action) - torch.log(1 - tanh_action.pow(2) + 1e-7)
        log_prob = log_prob.sum(dim=-1)
        action_np = tanh_action.cpu().numpy()
        return action_np, log_prob.item()

    def compute_returns(self, rewards, masks, values, next_value):
        R = next_value
        returns = []
        for step in reversed(range(len(rewards))):
            R = rewards[step] + self.gamma * R * masks[step]
            returns.insert(0, R)
        return returns

    def update(self, trajectories):
        states = torch.FloatTensor(np.array(trajectories['states'])).to(self.device)
        actions = torch.FloatTensor(np.array(trajectories['actions'])).to(self.device)
        old_log_probs = torch.FloatTensor(np.array(trajectories['log_probs'])).to(self.device)
        returns = torch.FloatTensor(np.array(trajectories['returns'])).to(self.device)
        values = torch.FloatTensor(np.array(trajectories['values'])).to(self.device)
        advantages = returns - values

        # Normalize advantages
        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)

        # PPO update
        for _ in range(4):  # Number of epochs
            mean, std, current_values = self.model(states)
            dist = Normal(mean, std)
            new_log_probs = dist.log_prob(actions)
            tanh_actions = torch.tanh(actions)
            new_log_probs -= torch.log(1 - tanh_actions.pow(2) + 1e-7)
            new_log_probs = new_log_probs.sum(dim=-1)
            entropy = dist.entropy().sum(dim=-1).mean()

            ratio = (new_log_probs - old_log_probs).exp()

            # Surrogate function
            surr1 = ratio * advantages
            surr2 = torch.clamp(ratio, 1 - self.eps_clip, 1 + self.eps_clip) * advantages
            actor_loss = -torch.min(surr1, surr2).mean()
            critic_loss = self.c1 * (returns - current_values.squeeze()).pow(2).mean()
            loss = actor_loss + critic_loss - self.c2 * entropy

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()


// File: environment.py
# File: environment.py
import numpy as np
import asyncio

class TradingEnvironment:
    def __init__(self, lnn_output_queue, initial_balance=10000, max_leverage=10):
        self.lnn_output_queue = lnn_output_queue
        self.initial_balance = initial_balance
        self.max_leverage = max_leverage

    async def reset(self):
        self.balance = self.initial_balance
        self.position = 0.0  # Current position size (positive for long, negative for short)
        self.entry_price = 0.0
        self.margin = 0.0
        self.equity = self.initial_balance
        self.margin_level = 100.0
        self.history = []
        lnn_output = await self._get_lnn_output()
        self.current_state = self._get_state(lnn_output)
        return self.current_state

    async def step(self, action):
        # action is expected to be a scalar in [-1, 1]
        lnn_output = await self._get_lnn_output()
        market_price = self._get_market_price(lnn_output)
        # Process action
        # action > 0: buy (long), action < 0: sell (short), action == 0: hold
        position_change = action.item() * self.max_leverage  # Scale action to leverage
        # Update position
        self.position += position_change
        self.entry_price = market_price  # Update entry price
        # Compute reward
        reward = self._compute_reward(market_price)
        # Update equity
        self.equity += reward
        self.history.append((self.position, market_price, reward))
        # Check if done (e.g., if balance below zero)
        done = self.equity <= 0
        info = {}
        # Update state
        self.current_state = self._get_state(lnn_output)
        return self.current_state, reward, done, info

    async def _get_lnn_output(self):
        lnn_output = await self.lnn_output_queue.get()
        self.lnn_output_queue.task_done()
        return lnn_output  # Assuming lnn_output is a scalar indicator

    def _get_market_price(self, lnn_output):
        # For simplicity, use the LNN output as a proxy for market price
        # In practice, you would get the market price from actual data
        return lnn_output

    def _compute_reward(self, market_price):
        # Compute reward based on position and market price change
        price_change = market_price - self.entry_price
        reward = self.position * price_change
        return reward

    def _get_state(self, lnn_output):
        # Construct the state representation
        # State includes LNN output, current position, and equity
        state = np.array([lnn_output, self.position, self.equity], dtype=np.float32)
        return state


// File: error_handler.py
# File: error_handler.py
import logging

class ErrorHandler:
    def __init__(self):
        self.logger = logging.getLogger("ErrorHandler")

    def handle_error(self, message: str, exc_info: bool = False, **context):
        context_info = ' | '.join([f"{key}={value}" for key, value in context.items()])
        full_message = f"{message} | {context_info}" if context else message
        self.logger.error(full_message, exc_info=exc_info)


// File: main.py
# File: main.py
import asyncio
import logging
import os
from dotenv import load_dotenv
from data.mexc_websocket_connector import MexcWebsocketConnector
from data.data_processor import DataProcessor
from error_handler import ErrorHandler

def load_configuration():
    load_dotenv(os.path.join(os.path.dirname(__file__), 'configs/.env'))
    symbols = os.getenv("SYMBOLS", "BTCUSDT").split(",")
    timeframes = os.getenv("TIMEFRAMES", "Min1").split(",")
    return symbols, timeframes

def validate_configuration(symbols, timeframes):
    if not symbols or symbols == ['']:
        raise ValueError("SYMBOLS must be defined in the .env file.")
    if not timeframes or timeframes == ['']:
        raise ValueError("TIMEFRAMES must be defined in the .env file.")

async def main():
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,  # Change to logging.DEBUG for more verbosity
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("app.log"),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger("Main")

    symbols, timeframes = load_configuration()
    try:
        validate_configuration(symbols, timeframes)
    except ValueError as ve:
        logger.error(f"Configuration Error: {ve}")
        return
    logger.info(f"Loaded configuration: Symbols={symbols}, Timeframes={timeframes}")

    # Initialize components
    data_queue = asyncio.Queue()
    error_handler = ErrorHandler()

    processor = DataProcessor(data_queue, error_handler, symbols, timeframes)
    connector = MexcWebsocketConnector(data_queue, symbols, timeframes, error_handler)

    # Create tasks
    connector_task = asyncio.create_task(connector.connect())
    processor_task = asyncio.create_task(processor.run_lnn())  # Run the LNN processing loop

    tasks = [connector_task, processor_task]

    try:
        await asyncio.gather(*tasks)
    except KeyboardInterrupt:
        logger.info("Pipeline terminated by user.")
    except Exception as e:
        error_handler.handle_error(f"Unexpected error in main: {e}", exc_info=True)
    finally:
        for task in tasks:
            task.cancel()
        await asyncio.gather(*tasks, return_exceptions=True)
        logger.info("Shutdown complete.")

if __name__ == "__main__":
    asyncio.run(main())


// File: data\data_processor.py
# File: data/data_processor.py
import asyncio
from typing import Dict, Any, List
from error_handler import ErrorHandler
import logging
from models.lnn_model import LiquidNeuralNetwork
import torch
import numpy as np
from sklearn.preprocessing import StandardScaler

# Constants for LNN
INPUT_SIZE = 30  # Adjust based on your selected features
HIDDEN_SIZE = 256  # Should match the hidden_size in the model
OUTPUT_SIZE = 1

# Precomputed scaling parameters (replace with actual means and stds)
feature_means = np.array([0.0] * INPUT_SIZE)
feature_stds = np.array([1.0] * INPUT_SIZE)

class DataProcessor:
    def __init__(
        self,
        data_queue: asyncio.Queue,
        error_handler: ErrorHandler,
        symbols: List[str],
        timeframes: List[str]
    ):
        self.data_queue = data_queue
        self.error_handler = error_handler
        self.symbols = symbols
        self.timeframes = timeframes
        self.logger = logging.getLogger("DataProcessor")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.lnn = LiquidNeuralNetwork(
            input_size=INPUT_SIZE,
            hidden_size=HIDDEN_SIZE,
            output_size=OUTPUT_SIZE
        ).to(self.device)
        self.scaler = StandardScaler()
        # Initialize scaler with precomputed parameters
        self.scaler.mean_ = feature_means
        self.scaler.scale_ = feature_stds
        self.scaler.n_features_in_ = INPUT_SIZE

        # Batch processing parameters
        self.batch_size = 64  # Adjust based on your GPU capacity
        self.input_buffer = []

    def preprocess_data(self, data: Dict[str, Any]) -> torch.Tensor:
        """Preprocess data based on message type and extract features."""
        channel = data.get('c')
        if not channel:
            self.logger.warning(f"Data missing channel: {data}")
            return None

        try:
            if channel.startswith("spot@public.kline.v3.api"):
                return self._preprocess_kline_data(data)
            elif channel.startswith("spot@public.deals.v3.api"):
                return self._preprocess_deals_data(data)
            elif channel.startswith("spot@public.bookTicker.v3.api"):
                return self._preprocess_bookTicker_data(data)
            elif channel.startswith("spot@public.increase.depth.v3.api"):
                return self._preprocess_depth_data(data)
            else:
                self.logger.warning(f"Unknown channel: {channel}")
                return None

        except Exception as e:
            self.error_handler.handle_error(
                f"Preprocessing Error: {e}",
                exc_info=True,
                channel=channel
            )
            return None

    def _preprocess_kline_data(self, data: Dict[str, Any]) -> torch.Tensor:
        """Preprocess kline data."""
        kline_data = data.get('d', {}).get('k')
        if kline_data:
            try:
                features = [
                    float(kline_data['o']),  # Opening price
                    float(kline_data['c']),  # Closing price
                    float(kline_data['h']),  # Highest price
                    float(kline_data['l']),  # Lowest price
                    float(kline_data['v']),  # Quantity
                    float(kline_data['a']),  # Volume
                    int(kline_data['t']),    # Start time
                    int(kline_data['T']),    # End time
                    # Add more features as needed...
                ]
                features = features[:INPUT_SIZE] + [0] * (INPUT_SIZE - len(features))
                features = np.array(features)
                features_scaled = (features - self.scaler.mean_) / (self.scaler.scale_ + 1e-8)
                return torch.tensor(features_scaled, dtype=torch.float32)

            except (KeyError, TypeError) as e:
                self.error_handler.handle_error(
                    f"Kline Feature Error: {e}",
                    exc_info=True,
                    data=data
                )
        return None

    def _preprocess_deals_data(self, data: Dict[str, Any]) -> torch.Tensor:
        """Preprocess deals data."""
        deals_data = data.get('d', {}).get('deals')
        if deals_data and isinstance(deals_data, list):
            try:
                first_deal = deals_data[0]
                trade_side = int(first_deal['S'])
                is_buy = 1 if trade_side == 1 else 0
                features = [
                    float(first_deal['p']),   # Price
                    float(first_deal['v']),   # Quantity
                    int(first_deal['t']),     # Trade time
                    is_buy,                   # Trade side
                    # Add more features as needed...
                ]
                features = features[:INPUT_SIZE] + [0] * (INPUT_SIZE - len(features))
                features = np.array(features)
                features_scaled = (features - self.scaler.mean_) / (self.scaler.scale_ + 1e-8)
                return torch.tensor(features_scaled, dtype=torch.float32)

            except (KeyError, TypeError, IndexError) as e:
                self.error_handler.handle_error(
                    f"Deals Feature Error: {e}",
                    exc_info=True,
                    data=data
                )
        return None

    def _preprocess_bookTicker_data(self, data: Dict[str, Any]) -> torch.Tensor:
        """Preprocess book ticker data."""
        book_ticker_data = data.get('d')
        if book_ticker_data:
            try:
                features = [
                    float(book_ticker_data['a']),  # Best ask price
                    float(book_ticker_data['A']),  # Best ask quantity
                    float(book_ticker_data['b']),  # Best bid price
                    float(book_ticker_data['B']),  # Best bid quantity
                    # Add more features as needed...
                ]
                features = features[:INPUT_SIZE] + [0] * (INPUT_SIZE - len(features))
                features = np.array(features)
                features_scaled = (features - self.scaler.mean_) / (self.scaler.scale_ + 1e-8)
                return torch.tensor(features_scaled, dtype=torch.float32)

            except (KeyError, TypeError) as e:
                self.error_handler.handle_error(
                    f"BookTicker Feature Error: {e}",
                    exc_info=True,
                    data=data
                )
        return None

    def _preprocess_depth_data(self, data: Dict[str, Any]) -> torch.Tensor:
        """Preprocess depth data."""
        depth_data = data.get('d')
        if depth_data:
            try:
                asks = depth_data.get('asks', [])
                bids = depth_data.get('bids', [])
                num_levels = min(5, len(asks), len(bids))
                features = []
                for i in range(num_levels):
                    features.extend([
                        float(asks[i]['p']), float(asks[i]['v']),
                        float(bids[i]['p']), float(bids[i]['v'])
                    ])
                features = features[:INPUT_SIZE] + [0] * (INPUT_SIZE - len(features))
                features = np.array(features)
                features_scaled = (features - self.scaler.mean_) / (self.scaler.scale_ + 1e-8)
                return torch.tensor(features_scaled, dtype=torch.float32)

            except (KeyError, TypeError, IndexError) as e:
                self.error_handler.handle_error(
                    f"Depth Feature Error: {e}",
                    exc_info=True,
                    data=data
                )
        return None

    async def run_lnn(self):
        """Continuously process data through the LNN."""
        while True:
            try:
                data = await self.data_queue.get()

                input_tensor = self.preprocess_data(data)
                if input_tensor is not None:
                    self.input_buffer.append(input_tensor)

                if len(self.input_buffer) >= self.batch_size:
                    batch_tensor = torch.stack(self.input_buffer).to(self.device)
                    with torch.no_grad():
                        indicator_outputs = self.lnn(batch_tensor)
                        for indicator_output in indicator_outputs:
                            indicator_value = indicator_output.item()
                            self.logger.info(f"New Indicator: {indicator_value}")
                    self.input_buffer = []

                self.data_queue.task_done()

            except asyncio.CancelledError:
                self.logger.info("Data Processor task canceled.")
                break
            except Exception as e:
                self.error_handler.handle_error(
                    f"LNN Processing Error: {e}",
                    exc_info=True
                )


// File: data\mexc_websocket_connector.py
# File: data/mexc_websocket_connector.py
import asyncio
import websockets
import json
from typing import List
from error_handler import ErrorHandler
import logging
import time

class MexcWebsocketConnector:
    def __init__(
        self,
        data_queue: asyncio.Queue,
        symbols: List[str],
        timeframes: List[str],
        error_handler: ErrorHandler
    ):
        self.data_queue = data_queue
        self.symbols = symbols
        self.timeframes = timeframes
        self.error_handler = error_handler
        self.logger = logging.getLogger("MexcWebsocketConnector")
        self.uri = "wss://wbs.mexc.com/ws"
        self.ping_interval = 60

    async def connect(self):
        while True:
            try:
                async with websockets.connect(self.uri, ping_interval=None) as websocket:
                    await self.subscribe_channels(websocket)
                    ping_task = asyncio.create_task(self.send_ping(websocket))
                    async for message in websocket:
                        try:
                            data = json.loads(message)
                            if data.get("msg") == "PONG":
                                self.logger.debug("Received PONG from server.")
                                continue
                            await self.data_queue.put(data)
                            self.logger.debug(f"Received data: {data}")
                        except json.JSONDecodeError as e:
                            self.error_handler.handle_error(
                                f"JSON decode error: {e}",
                                exc_info=True
                            )
            except websockets.exceptions.ConnectionClosedError as e:
                self.error_handler.handle_error(
                    f"WebSocket connection closed unexpectedly: {e}",
                    exc_info=True
                )
                self.logger.warning("WebSocket connection closed. Reconnecting in 5 seconds...")
                await asyncio.sleep(5)
            except Exception as e:
                self.error_handler.handle_error(
                    f"Unexpected error in WebSocket connection: {e}",
                    exc_info=True
                )
                self.logger.error("Unexpected error. Reconnecting in 5 seconds...")
                await asyncio.sleep(5)

    async def subscribe_channels(self, websocket):
        subscribe_params = self._generate_subscribe_params()
        max_subscriptions = 30
        for i in range(0, len(subscribe_params), max_subscriptions):
            batch = subscribe_params[i:i + max_subscriptions]
            subscribe_message = {
                "method": "SUBSCRIPTION",
                "params": batch,
                "id": int(time.time())
            }
            await websocket.send(json.dumps(subscribe_message))
            self.logger.info(f"Subscribed to {len(batch)} channels.")

            try:
                response = await asyncio.wait_for(websocket.recv(), timeout=10)
                response_data = json.loads(response)
                if response_data.get("code") == 0:
                    self.logger.info(f"Subscription successful: {response_data.get('msg')}")
                else:
                    self.error_handler.handle_error(
                        f"Subscription failed: {response_data}",
                        exc_info=False
                    )
            except asyncio.TimeoutError:
                self.error_handler.handle_error(
                    "Subscription acknowledgment timed out.",
                    exc_info=False
                )

    def _generate_subscribe_params(self) -> List[str]:
        channels = []
        for symbol in self.symbols:
            symbol = symbol.upper()
            channels.append(f"spot@public.increase.depth.v3.api@{symbol}")
            channels.append(f"spot@public.deals.v3.api@{symbol}")
            channels.append(f"spot@public.bookTicker.v3.api@{symbol}")
            for timeframe in self.timeframes:
                channels.append(f"spot@public.kline.v3.api@{symbol}@{timeframe}")
        return channels

    async def send_ping(self, websocket):
        try:
            while True:
                ping_message = {
                    "method": "PING"
                }
                await websocket.send(json.dumps(ping_message))
                self.logger.debug("Sent PING to server.")
                await asyncio.sleep(self.ping_interval)
        except asyncio.CancelledError:
            self.logger.info("Ping task cancelled.")
        except Exception as e:
            self.error_handler.handle_error(
                f"Error in PING/PONG mechanism: {e}",
                exc_info=True
            )
            raise e


// File: data\__init__.py
# File: data/__init__.py
from .mexc_websocket_connector import MexcWebsocketConnector
from .data_processor import DataProcessor

__all__ = ['MexcWebsocketConnector', 'DataProcessor']


// File: models\lnn_model.py
# File: models/lnn_model.py
import torch
import torch.nn as nn
from torchdiffeq import odeint_adjoint as odeint  # Using adjoint method for memory efficiency

class ODEFunc(nn.Module):
    def __init__(self, hidden_size):
        super(ODEFunc, self).__init__()
        self.fc1 = nn.Linear(hidden_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.nonlinearity = nn.ELU()

    def forward(self, t, x):
        out = self.nonlinearity(self.fc1(x))
        out = self.nonlinearity(self.fc2(out))
        return out

class LiquidNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LiquidNeuralNetwork, self).__init__()
        self.input_layer = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ELU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ELU()
        )
        self.ode_func = ODEFunc(hidden_size)
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.ELU(),
            nn.Linear(hidden_size, output_size),
            nn.Tanh()  # Output between -1 and 1
        )
        # Residual connection
        self.res_connection = nn.Linear(input_size, hidden_size)

    def forward(self, x):
        t = torch.tensor([0.0, 1.0], dtype=torch.float32).to(x.device)
        residual = self.res_connection(x)
        x = self.input_layer(x)
        x = x + residual  # Adding residual connection
        ode_sol = odeint(
            self.ode_func,
            x,
            t,
            method='rk4',
            options={'step_size': 0.1}
        )
        x = ode_sol[-1]
        x = self.output_layer(x)
        return x


// File: models\__init__.py
# File: models/__init__.py
from .lnn_model import LiquidNeuralNetwork

__all__ = ['LiquidNeuralNetwork']


