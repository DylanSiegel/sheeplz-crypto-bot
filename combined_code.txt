**File Tree (Relevant Files Only)**
  .
    - viz.py
  data\raw
    - btc_usdt_1m_processed.csv
// File: viz.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from pathlib import Path
import plotly.express as px
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
from typing import List, Optional, Literal
import logging
from tqdm import tqdm

# Logging Configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("market_visualizer_optimized.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Device Configuration
if torch.cuda.is_available():
    device = torch.device('cuda')
    torch.backends.cudnn.benchmark = True
    logger.info("CUDA is available. Running on GPU.")
else:
    device = torch.device('cpu')
    logger.info("CUDA is not available. Running on CPU.")


class HypersphericalEncoder(nn.Module):
    def __init__(
            self,
            projection_dim: int = 128,
            sequence_length: int = 60,
            n_price_features: int = 5,
            n_indicator_features: int = 7,
            temperature: float = 0.07,
            device: torch.device = device,  # Use the global device variable
            price_scaler: Optional[StandardScaler] = None,
            indicator_scaler: Optional[StandardScaler] = None
    ):
        super().__init__()
        self.projection_dim = projection_dim
        self.sequence_length = sequence_length
        self.n_price_features = n_price_features
        self.n_indicator_features = n_indicator_features
        self.temperature = temperature
        self.device = device

        self.price_scaler = price_scaler
        self.indicator_scaler = indicator_scaler

        # Initialize bidirectional GRU to capture temporal dependencies
        self.gru = nn.GRU(
            input_size=n_price_features + n_indicator_features,
            hidden_size=projection_dim * 2,
            num_layers=1,
            batch_first=True,
            bidirectional=True
        ).to(device)

        # Neural network components
        self.projection1 = nn.Linear(projection_dim * 4, projection_dim * 2).to(device)
        self.layer_norm = nn.LayerNorm(projection_dim * 2).to(device)
        self.projection2 = nn.Linear(projection_dim * 2, projection_dim).to(device)

        # Set to eval mode and disable gradients
        self.eval()
        self._set_requires_grad(False)

    def _set_requires_grad(self, requires_grad: bool):
        for param in self.parameters():
            param.requires_grad_(requires_grad)

    @torch.no_grad()
    def encode_batch(self, sequences: np.ndarray, lengths: Optional[List[int]] = None) -> torch.Tensor:
        if sequences.ndim == 2:
            sequences = sequences.reshape(1, *sequences.shape)

        # Split and scale features
        price_data = sequences[:, :, :self.n_price_features]
        indicator_data = sequences[:, :, self.n_price_features:self.n_price_features + self.n_indicator_features]

        if self.price_scaler is None or self.indicator_scaler is None:
            raise ValueError("Scalers have not been fitted. Please fit scalers before encoding.")

        price_scaled = self.price_scaler.transform(price_data.reshape(-1, self.n_price_features))
        indicator_scaled = self.indicator_scaler.transform(indicator_data.reshape(-1, self.n_indicator_features))

        price_scaled = price_scaled.reshape(sequences.shape[0], sequences.shape[1], -1)
        indicator_scaled = indicator_scaled.reshape(sequences.shape[0], sequences.shape[1], -1)

        combined_features = np.concatenate([price_scaled, indicator_scaled], axis=-1)
        combined_features = torch.FloatTensor(combined_features).to(self.device)

        if lengths is not None:
            packed_features = pack_padded_sequence(combined_features, lengths, batch_first=True, enforce_sorted=False)
        else:
            packed_features = combined_features

        packed_output, gru_hidden = self.gru(packed_features)
        if lengths is not None:
            output, _ = pad_packed_sequence(packed_output, batch_first=True)
        else:
            output = packed_output

        gru_hidden = torch.cat((gru_hidden[-2], gru_hidden[-1]), dim=1)

        hidden = self.projection1(gru_hidden)
        hidden = F.relu(self.layer_norm(hidden))
        projected = self.projection2(hidden)

        scaled = projected / self.temperature
        normalized = F.normalize(scaled, p=2, dim=1)

        return normalized, output


class MarketVisualizer:
    def __init__(
            self,
            data_path: str = "data/raw/btc_usdt_1m_processed.csv",
            batch_size: int = 256,
            sequence_length: int = 64,
            hidden_size: int = 128,
            device: torch.device = device,  # Use the global device variable
            scaling_method: Literal["standard", "minmax"] = "standard"
    ):
        logger.info(f"Initializing MarketVisualizer with data from {data_path}")
        self.data_path = Path(data_path)
        self.batch_size = batch_size
        self.device = device
        self.sequence_length = sequence_length
        self.hidden_size = hidden_size
        self.scaling_method = scaling_method

        if not self.data_path.exists():
            raise FileNotFoundError(f"Data file not found: {data_path}")

        logger.info("Loading and preprocessing market data...")
        self.df = pd.read_csv(self.data_path)
        self.df['timestamp'] = pd.to_datetime(self.df['open_time'])
        self.df.set_index('timestamp', inplace=True)

        self.price_columns = ['open', 'high', 'low', 'close', 'volume']
        self.indicator_columns = [
            'quote_asset_volume', 'number_of_trades',
            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume',
            'macd', 'rsi_14', 'ema_10'
        ]

        logger.info("Converting data to numeric format...")
        all_numeric_columns = self.price_columns + self.indicator_columns
        for col in tqdm(all_numeric_columns, desc="Processing columns"):
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')

        self.analysis_df = self.df.copy()
        logger.info(f"Analysis dataframe shape: {self.analysis_df.shape}")

        if self.scaling_method == "standard":
            self.price_scaler = StandardScaler()
            self.indicator_scaler = StandardScaler()
        elif self.scaling_method == "minmax":
            self.price_scaler = MinMaxScaler()
            self.indicator_scaler = MinMaxScaler()
        else:
            raise ValueError("Invalid scaling_method. Choose 'standard' or 'minmax'.")

        self._fit_scalers()

        self.encoder = HypersphericalEncoder(
            n_price_features=len(self.price_columns),
            n_indicator_features=len(self.indicator_columns),
            projection_dim=self.hidden_size,
            sequence_length=self.sequence_length,
            device=device,
            price_scaler=self.price_scaler,
            indicator_scaler=self.indicator_scaler
        ).to(device)

        self.all_timestamps = []  # Add this for tracking which klines are encoded

    def _fit_scalers(self):
        logger.info("Creating sequences for scaler fitting...")
        sequences = []
        stride = 1000
        n_sequences = (len(self.analysis_df) - self.sequence_length) // stride

        for i in range(n_sequences):
            idx = i * stride
            sequence = self.analysis_df.iloc[idx:idx + self.sequence_length].values
            sequences.append(sequence)

        price_data = self.analysis_df[self.price_columns].values.reshape(-1, len(self.price_columns))
        indicator_data = self.analysis_df[self.indicator_columns].values.reshape(-1, len(self.indicator_columns))

        self.price_scaler.fit(np.nan_to_num(price_data))
        self.indicator_scaler.fit(np.nan_to_num(indicator_data))
        logger.info("Scalers fitted successfully")

    def visualize_hypersphere(self, n_samples: int = 10000, projection_method: str = 'pca', perplexity: int = 50):
        logger.info(f"Creating hypersphere visualization using {projection_method}")
        max_samples = min(n_samples, len(self.analysis_df) - self.encoder.sequence_length)
        n_batches = (max_samples + self.batch_size - 1) // self.batch_size

        encoded_states = []
        all_hidden_states = []
        logger.info(f"Encoding {max_samples} market states in batches...")

        all_hidden_states_for_viz = []  # Separate list for visualization

        for batch_idx in tqdm(range(n_batches), desc="Processing batches"):
            start_idx = batch_idx * self.batch_size
            end_idx = min(start_idx + self.batch_size, max_samples)

            batch_sequences = []
            lengths = []
            for i in range(start_idx, end_idx):
                seq_len = np.random.randint(1, self.encoder.sequence_length + 1)
                sequence = self.analysis_df.iloc[i:i + seq_len].values
                max_length = self.encoder.sequence_length
                if len(sequence) < max_length:
                    sequence = np.pad(sequence, [(0, max_length - len(sequence)), (0,0)], mode="constant")
                lengths.append(len(sequence))
                batch_sequences.append(sequence)

            batch_array = np.array(batch_sequences)
            try:
                batch_encoded, hidden_states = self.encoder.encode_batch(batch_array, lengths=lengths)
                encoded_states.append(batch_encoded.cpu())

                hidden_states_cpu = hidden_states.cpu().numpy()
                all_hidden_states_for_viz.extend(hidden_states_cpu)
                self.all_timestamps.extend(self.df['open_time'][start_idx:end_idx].values)

            except Exception as e:
                logger.error(f"Error encoding batch {batch_idx}: {str(e)}")
                continue

        if not encoded_states:
            raise ValueError("No states were successfully encoded")

        if len(encoded_states) > 0:
            all_states = torch.cat(encoded_states, dim=0).numpy()
            all_hidden_states = torch.cat([torch.tensor(h) for h in all_hidden_states_for_viz], dim=0).numpy()
        else:
            raise ValueError("No valid encoded states were found, unable to proceed with visualization.")

        all_hidden_states = torch.cat(all_hidden_states, dim=0).view(-1, all_hidden_states.shape[-1]).numpy()
        logger.info(f"Successfully encoded {len(all_states)} states")

        if projection_method == 'pca':
            reducer = PCA(n_components=3)
            reduced_states = reducer.fit_transform(all_hidden_states)
            hover_data = {f"Feature {i+1}": all_states[:, i] for i in range(all_states.shape[1])}
        elif projection_method == 'tsne':
            reducer = TSNE(n_components=3, perplexity=perplexity, n_jobs=-1, learning_rate='auto', init='pca') # Add PCA init and learning_rate
            reduced_states = reducer.fit_transform(all_hidden_states_for_viz)

            # Reshape reduced_states if using all hidden states for t-SNE:
            if len(reduced_states) > len(all_states):
                reduced_states = reduced_states.reshape(len(all_states), self.sequence_length, -1)
            hover_data = {f"Feature {i + 1}": all_states[:, i] for i in range(all_states.shape[1])}

        # Plotly Visualization with Animation Frames (if using all hidden states for TSNE)
        if isinstance(reduced_states, np.ndarray) and reduced_states.shape[1] == 3:  # Standard scatter plot
            fig = px.scatter_3d(
                x=reduced_states[:, 0],
                y=reduced_states[:, 1],
                z=reduced_states[:, 2],
                color=self.analysis_df['macd'][:len(reduced_states)],  # Color based on MACD for first sequence item
                hover_data=hover_data,  # Add hover data (check data length)
                title=f'Encoded States Visualization ({projection_method.upper()})'
            )
        elif isinstance(reduced_states, np.ndarray) and reduced_states.shape[2] == 3:  # Sequence Scatter Plot
            fig = px.scatter_3d(
                x=reduced_states[:, :, 0].flatten(),
                y=reduced_states[:, :, 1].flatten(),
                z=reduced_states[:, :, 2].flatten(),
                animation_frame=np.repeat(np.arange(reduced_states.shape[0]), reduced_states.shape[1]),
                color=np.repeat(self.analysis_df['macd'][:reduced_states.shape[0]].values, reduced_states.shape[1]),
                hover_data={"Timestamp": np.repeat(self.all_timestamps[:reduced_states.shape[0]], reduced_states.shape[1])},
                title=f'Encoded States Visualization ({projection_method.upper()})'
            )
        else:
            logger.warning(f"Shape of reduced states: {np.shape(reduced_states)} not suitable for visualization")

        return fig


def main():
    try:
        viz = MarketVisualizer(sequence_length=128, hidden_size=256, scaling_method="minmax")
        output_dir = Path("visualizations")
        output_dir.mkdir(exist_ok=True)
        logger.info(f"Created output directory: {output_dir}")

        logger.info("Creating hypersphere visualization...")
        hypersphere_fig = viz.visualize_hypersphere(n_samples=10000, projection_method='tsne', perplexity=50)
        hypersphere_fig.write_html(output_dir / "hypersphere_tsne.html")

        logger.info("Visualizations completed successfully")
        print("\nVisualizations saved to 'visualizations' directory")

    except Exception as e:
        logger.error(f"Error creating visualizations: {str(e)}", exc_info=True)
        raise


if __name__ == "__main__":
    main()


// File: data\raw\btc_usdt_1m_processed.csv
// Snippet:
                open_time    open    high     low   close  volume                       close_time  quote_asset_volume  number_of_trades  taker_buy_base_asset_volume  taker_buy_quote_asset_volume  ignore  rsi_6  rsi_14  rsi_24      macd  macd_signal  macd_hist  bb_upper  bb_lower       ema_5      ema_10      ema_20      ema_60     ema_120
2020-01-01 00:00:00+00:00 7189.43 7190.52 7177.00 7182.44 246.092 2020-01-01 00:00:59.999000+00:00        1.767430e+06               336                       46.630                  334813.19820       0    0.0     0.0     0.0  0.000000     0.000000   0.000000       NaN       NaN 7182.440000 7182.440000 7182.440000 7182.440000 7182.440000
2020-01-01 00:01:00+00:00 7182.43 7182.44 7178.75 7179.01  70.909 2020-01-01 00:01:59.999000+00:00        5.091458e+05               140                       32.597                  234063.27884       0    0.0     0.0     0.0 -0.273618    -0.054724  -0.218895       NaN       NaN 7181.296667 7181.816364 7182.113333 7182.327541 7182.383306
2020-01-01 00:02:00+00:00 7179.01 7179.01 7175.25 7177.93  99.420 2020-01-01 00:02:59.999000+00:00        7.135396e+05               148                       16.311                  117066.92118       0    0.0     0.0     0.0 -0.571027    -0.157984  -0.413043       NaN       NaN 7180.174444 7181.109752 7181.714921 7182.183359 7182.309697
2020-01-01 00:03:00+00:00 7177.77 7182.60 7177.00 7181.11  69.330 2020-01-01 00:03:59.999000+00:00        4.977934e+05               104                       43.723                  313920.02981       0    0.0     0.0     0.0 -0.543857    -0.235159  -0.308698       NaN       NaN 7180.486296 7181.109797 7181.657309 7182.148167 7182.289868
2020-01-01 00:04:00+00:00 7179.10 7179.10 7172.94 7175.25  97.368 2020-01-01 00:04:59.999000+00:00        6.986274e+05               193                       36.616                  262734.68999       0    0.0     0.0     0.0 -0.983837    -0.384895  -0.598942       NaN       NaN 7178.740864 7180.044379 7181.047089 7181.921998 7182.173506

