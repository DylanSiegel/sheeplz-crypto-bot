**File Tree (Relevant Files Only)**
  .
    - ai_module.py
    - dataset.py
    - main.py
    - visualization.py
  data\raw
    - btc_usdt_1m_processed.csv
// File: ai_module.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class HypersphericalEncoder(nn.Module):
    def __init__(self, projection_dim=128, sequence_length=60, n_price_features=5, n_indicator_features=7, temperature=0.07, device='cuda'):
        super().__init__()
        self.projection_dim = projection_dim
        self.sequence_length = sequence_length
        self.n_price_features = n_price_features
        self.n_indicator_features = n_indicator_features
        self.temperature = temperature
        self.device = device

        self.gru = nn.GRU(
            input_size=n_price_features + n_indicator_features,
            hidden_size=projection_dim * 2,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.3
        ).to(device)

        self.projection1 = nn.Linear(projection_dim * 4, projection_dim * 2).to(device)
        self.layer_norm = nn.LayerNorm(projection_dim * 2).to(device)
        self.projection2 = nn.Linear(projection_dim * 2, projection_dim).to(device)

        self._init_weights()
        self.eval()
        torch.set_grad_enabled(False)

    def _init_weights(self):
        nn.init.xavier_uniform_(self.projection1.weight)
        nn.init.zeros_(self.projection1.bias)
        nn.init.xavier_uniform_(self.projection2.weight)
        nn.init.zeros_(self.projection2.bias)

    def forward(self, x, lengths=None):
        with torch.autocast(device_type='cuda', dtype=torch.float16):
            if lengths is not None:
                packed_features = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)
                packed_output, gru_hidden = self.gru(packed_features)
                output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)
            else:
                output, gru_hidden = self.gru(x)

            gru_hidden = torch.cat((gru_hidden[-2], gru_hidden[-1]), dim=1)
            hidden = F.relu(self.layer_norm(self.projection1(gru_hidden)))
            projected = self.projection2(hidden)
            normalized = F.normalize(projected / self.temperature, p=2, dim=1)

            return normalized, output

    @torch.no_grad()
    def encode_batch(self, sequences):
        sequences = sequences.to(self.device, non_blocking=True)
        return self(sequences)


// File: dataset.py
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import gc

class MarketDataset(Dataset):
    def __init__(self, data_array, timestamps, sequence_length, price_scaler, indicator_scaler, cache_size=1000):
        self.data_array = data_array
        self.timestamps = timestamps
        self.sequence_length = sequence_length
        self.price_scaler = price_scaler
        self.indicator_scaler = indicator_scaler
        self.max_index = len(data_array) - sequence_length
        self.cache_size = cache_size
        self.cache = {}
        self.n_price_features = len(self.price_scaler.scale_)

    def __len__(self):
        return self.max_index

    def _process_sequence(self, idx):
        if idx in self.cache:
            return self.cache[idx]

        sequence = self.data_array[idx:idx + self.sequence_length]
        price_data = sequence[:, :self.n_price_features]
        indicator_data = sequence[:, self.n_price_features:]

        price_scaled = self.price_scaler.transform(price_data)
        indicator_scaled = self.indicator_scaler.transform(indicator_data)

        combined = np.hstack((price_scaled, indicator_scaled)).astype(np.float32)
        tensor_data = torch.from_numpy(combined)

        if len(self.cache) >= self.cache_size:
            self.cache.pop(next(iter(self.cache)))
        timestamp = self.timestamps[idx + self.sequence_length - 1]
        timestamp_float = timestamp.timestamp()
        self.cache[idx] = (tensor_data, timestamp_float)

        return tensor_data, timestamp_float

    def __getitem__(self, idx):
        return self._process_sequence(idx)

def load_and_preprocess_data(data_path, scaling_method='standard'):
    df = pd.read_csv(
        data_path,
        parse_dates=['open_time', 'close_time'],
        dtype_backend='pyarrow'
    )

    df['timestamp'] = pd.to_datetime(df['open_time'])
    df.set_index('timestamp', inplace=True)
    timestamps = df.index

    price_columns = ['open', 'high', 'low', 'close', 'volume']
    indicator_columns = [
        'quote_asset_volume', 'number_of_trades',
        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume',
        'macd', 'rsi_14', 'ema_10'
    ]

    analysis_df = df[price_columns + indicator_columns].copy()
    data_array = analysis_df.values

    price_scaler = StandardScaler() if scaling_method == "standard" else MinMaxScaler()
    indicator_scaler = StandardScaler() if scaling_method == "standard" else MinMaxScaler()

    price_data = data_array[:, :len(price_columns)]
    indicator_data = data_array[:, len(price_columns):]

    price_scaler.fit(np.nan_to_num(price_data))
    indicator_scaler.fit(np.nan_to_num(indicator_data))

    del df
    del analysis_df
    gc.collect()

    return data_array, timestamps, price_columns, indicator_columns, price_scaler, indicator_scaler


// File: main.py
import torch
from torch.utils.data import DataLoader, Subset
import numpy as np
from pathlib import Path
import logging
from tqdm.auto import tqdm
import multiprocessing as mp
import os
import sys

from ai_module import HypersphericalEncoder
from dataset import MarketDataset, load_and_preprocess_data
from visualization import Visualizer

def setup_logging():
    logger = logging.getLogger(__name__)
    if not logger.hasHandlers():
        logger.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler = logging.FileHandler("market_visualizer_optimized.log")
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)
    return logger

logger = setup_logging()

def get_num_workers():
    if os.name == 'nt':
        return min(4, mp.cpu_count())
    return min(mp.cpu_count(), 8)

NUM_WORKERS = get_num_workers()
logger.info(f"Using {NUM_WORKERS} workers for data loading")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"Using device: {device}")

def main():
    try:
        data_path = "data/raw/btc_usdt_1m_processed.csv"
        batch_size = 512
        sequence_length = 64
        hidden_size = 256
        scaling_method = "minmax"
        cache_size = 1000
        use_amp = True

        data_array, timestamps, price_columns, indicator_columns, price_scaler, indicator_scaler = load_and_preprocess_data(data_path, scaling_method)

        dataset = MarketDataset(
            data_array=data_array,
            timestamps=timestamps,
            sequence_length=sequence_length,
            price_scaler=price_scaler,
            indicator_scaler=indicator_scaler,
            cache_size=cache_size
        )

        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=NUM_WORKERS,
            pin_memory=True if torch.cuda.is_available() else False,
            persistent_workers=True if NUM_WORKERS > 0 else False
        )

        encoder = HypersphericalEncoder(
            projection_dim=hidden_size,
            sequence_length=sequence_length,
            n_price_features=len(price_columns),
            n_indicator_features=len(indicator_columns),
            device=device
        )

        available_sequences = len(dataset)
        n_samples = 10000
        max_samples = min(n_samples, available_sequences)

        np.random.seed(42)
        indices = np.random.choice(dataset.max_index, size=max_samples, replace=False)

        subset_dataset = Subset(dataset, indices)
        subset_dataloader = DataLoader(
            subset_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True if torch.cuda.is_available() else False
        )

        encoded_states = []
        timestamps_list = []

        for batch_sequences, batch_timestamps in tqdm(subset_dataloader, desc="Encoding sequences"):
            if use_amp and torch.cuda.is_available():
                with torch.amp.autocast('cuda'):
                    batch_encoded, _ = encoder.encode_batch(batch_sequences)
            else:
                batch_encoded, _ = encoder.encode_batch(batch_sequences)

            encoded_states.append(batch_encoded.cpu().numpy())
            timestamps_list.extend(batch_timestamps.tolist())

        all_encoded = np.vstack(encoded_states)

        save_encoded = True
        encoded_save_path = "data/encoded_hypersphere.npy"
        if save_encoded:
            save_path = Path(encoded_save_path)
            save_path.parent.mkdir(parents=True, exist_ok=True)
            np.save(save_path, all_encoded)
            logger.info(f"Encoded data saved to {save_path}")

        visualizer = Visualizer(
            data_array=data_array,
            timestamps=timestamps,
            price_columns=price_columns,
            indicator_columns=indicator_columns,
            sequence_length=sequence_length
        )

        output_dir = Path("visualizations")
        output_dir.mkdir(exist_ok=True)
        logger.info(f"Output directory: {output_dir.resolve()}")

        with tqdm(total=2, desc="Generating visualizations") as pbar:
            fig_tsne = visualizer.visualize(
                encoded_states=all_encoded,
                timestamps=timestamps_list,
                indices=indices,
                color_feature="close",
                hover_features=['open', 'high', 'low', 'volume'],
                projection_method='tsne',
                create_subplots=True
            )

            if fig_tsne:
                output_path_tsne = output_dir / "market_visualization_tsne.html"
                fig_tsne.write_html(output_path_tsne)
                logger.info(f"t-SNE visualization saved at {output_path_tsne.resolve()}")
            pbar.update(1)

            fig_pca = visualizer.visualize(
                encoded_states=all_encoded,
                timestamps=timestamps_list,
                indices=indices,
                color_feature='rsi_14',
                hover_features=price_columns + indicator_columns,
                projection_method='pca',
                create_subplots=True
            )

            if fig_pca:
                output_path_pca = output_dir / "market_visualization_pca.html"
                fig_pca.write_html(output_path_pca)
                logger.info(f"PCA visualization saved at {output_path_pca.resolve()}")
            pbar.update(1)

    except Exception as e:
        logger.exception("Error in main execution")
        print(f"An error occurred: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()


// File: visualization.py
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

class Visualizer:
    def __init__(self, data_array, timestamps, price_columns, indicator_columns, sequence_length):
        self.data_array = data_array
        self.timestamps = timestamps
        self.price_columns = price_columns
        self.indicator_columns = indicator_columns
        self.sequence_length = sequence_length

    def _reduce_dimensions(self, encoded_states, method='pca', perplexity=50):
        if method == 'pca':
            reducer = PCA(n_components=3, random_state=42)
        elif method == 'tsne':
            reducer = TSNE(
                n_components=3,
                perplexity=min(perplexity, len(encoded_states) - 1),
                n_jobs=1,
                random_state=42,
                init='pca',
                method='barnes_hut'
            )
        else:
            raise ValueError(f"Unsupported projection method: {method}")

        return reducer.fit_transform(encoded_states)

    def visualize(self, encoded_states, timestamps, indices, color_feature='macd', hover_features=None, projection_method='pca', create_subplots=True):
        reduced_states = self._reduce_dimensions(encoded_states, method=projection_method)
        timestamps = [datetime.fromtimestamp(ts) for ts in timestamps]

        if create_subplots:
            return self._create_subplot_visualization(reduced_states, timestamps, indices, color_feature, hover_features)
        else:
            return self._create_single_visualization(reduced_states, timestamps, indices, color_feature, hover_features)

    def _create_subplot_visualization(self, reduced_states, timestamps, indices, color_feature, hover_features):
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                '3D View',
                'Top View (XY)',
                'Front View (XZ)',
                'Side View (YZ)'
            ),
            specs=[[{'type': 'scatter3d'}, {'type': 'scatter'}],
                   [{'type': 'scatter'}, {'type': 'scatter'}]]
        )

        color_data = self._get_feature_values(color_feature, indices)
        hover_data = self._prepare_hover_data(hover_features, timestamps, indices)

        fig.add_trace(
            go.Scatter3d(
                x=reduced_states[:, 0],
                y=reduced_states[:, 1],
                z=reduced_states[:, 2],
                mode='markers',
                marker=dict(
                    size=4,
                    color=color_data,
                    colorscale='Viridis',
                    showscale=True
                ),
                text=hover_data,
                hoverinfo='text'
            ),
            row=1, col=1
        )

        projections = [
            (0, 1, 1, 2),
            (0, 2, 2, 1),
            (1, 2, 2, 2)
        ]

        for x_idx, y_idx, row, col in projections:
            fig.add_trace(
                go.Scatter(
                    x=reduced_states[:, x_idx],
                    y=reduced_states[:, y_idx],
                    mode='markers',
                    marker=dict(
                        size=4,
                        color=color_data,
                        colorscale='Viridis',
                        showscale=False
                    ),
                    text=hover_data,
                    hoverinfo='text'
                ),
                row=row, col=col
            )

        fig.update_layout(
            title='Market State Visualization - Multiple Views',
            showlegend=False,
            height=800,
            width=1200,
            template='plotly_dark',
            margin=dict(l=20, r=20, t=40, b=20)
        )

        return fig

    def _create_single_visualization(self, reduced_states, timestamps, indices, color_feature, hover_features):
        color_data = self._get_feature_values(color_feature, indices)
        hover_data = self._prepare_hover_data(hover_features, timestamps, indices)

        fig = go.Figure(data=[
            go.Scatter3d(
                x=reduced_states[:, 0],
                y=reduced_states[:, 1],
                z=reduced_states[:, 2],
                mode='markers',
                marker=dict(
                    size=4,
                    color=color_data,
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title=color_feature)
                ),
                text=hover_data,
                hoverinfo='text'
            )
        ])

        fig.update_layout(
            title=f'Market State Visualization - {color_feature}',
            template='plotly_dark',
            scene=dict(
                xaxis_title='Component 1',
                yaxis_title='Component 2',
                zaxis_title='Component 3'
            ),
            width=1000,
            height=800,
            margin=dict(l=20, r=20, t=40, b=20)
        )

        return fig

    def _get_feature_values(self, feature, indices):
        feature_idx = self._get_feature_index(feature)
        return self.data_array[indices + self.sequence_length - 1, feature_idx]

    def _prepare_hover_data(self, hover_features, timestamps, indices):
        hover_text = []

        if hover_features is None:
            hover_features = []

        for i, ts in enumerate(timestamps):
            text_parts = [f"Time: {ts.strftime('%Y-%m-%d %H:%M:%S')}"]

            for feature in hover_features:
                feature_idx = self._get_feature_index(feature)
                value = self.data_array[indices[i] + self.sequence_length - 1, feature_idx]
                text_parts.append(f"{feature}: {value:.2f}")

            hover_text.append("<br>".join(text_parts))

        return hover_text

    def _get_feature_index(self, feature):
        if feature in self.price_columns:
            return self.price_columns.index(feature)
        elif feature in self.indicator_columns:
            return len(self.price_columns) + self.indicator_columns.index(feature)
        else:
            raise ValueError(f"Feature '{feature}' not found in price or indicator columns.")


// File: data\raw\btc_usdt_1m_processed.csv
// Snippet:
                open_time    open    high     low   close  volume                       close_time  quote_asset_volume  number_of_trades  taker_buy_base_asset_volume  taker_buy_quote_asset_volume  ignore  rsi_6  rsi_14  rsi_24      macd  macd_signal  macd_hist  bb_upper  bb_lower       ema_5      ema_10      ema_20      ema_60     ema_120
2020-01-01 00:00:00+00:00 7189.43 7190.52 7177.00 7182.44 246.092 2020-01-01 00:00:59.999000+00:00        1.767430e+06               336                       46.630                  334813.19820       0    0.0     0.0     0.0  0.000000     0.000000   0.000000       NaN       NaN 7182.440000 7182.440000 7182.440000 7182.440000 7182.440000
2020-01-01 00:01:00+00:00 7182.43 7182.44 7178.75 7179.01  70.909 2020-01-01 00:01:59.999000+00:00        5.091458e+05               140                       32.597                  234063.27884       0    0.0     0.0     0.0 -0.273618    -0.054724  -0.218895       NaN       NaN 7181.296667 7181.816364 7182.113333 7182.327541 7182.383306
2020-01-01 00:02:00+00:00 7179.01 7179.01 7175.25 7177.93  99.420 2020-01-01 00:02:59.999000+00:00        7.135396e+05               148                       16.311                  117066.92118       0    0.0     0.0     0.0 -0.571027    -0.157984  -0.413043       NaN       NaN 7180.174444 7181.109752 7181.714921 7182.183359 7182.309697
2020-01-01 00:03:00+00:00 7177.77 7182.60 7177.00 7181.11  69.330 2020-01-01 00:03:59.999000+00:00        4.977934e+05               104                       43.723                  313920.02981       0    0.0     0.0     0.0 -0.543857    -0.235159  -0.308698       NaN       NaN 7180.486296 7181.109797 7181.657309 7182.148167 7182.289868
2020-01-01 00:04:00+00:00 7179.10 7179.10 7172.94 7175.25  97.368 2020-01-01 00:04:59.999000+00:00        6.986274e+05               193                       36.616                  262734.68999       0    0.0     0.0     0.0 -0.983837    -0.384895  -0.598942       NaN       NaN 7178.740864 7180.044379 7181.047089 7181.921998 7182.173506

