Develop a data pipeline that pulls multiple kline data from the MEXC WebSocket API across timeframes (1 min, 15 min, 30 min, 4 hr, daily, weekly, monthly), integrates technical analysis (TA) for each timeframe, and consolidates it into a single, processed feed. Ensure all data is fully processed before being fed into the Graph-Based Metanetwork (GMN) module, with the data pipeline aligned with MEXC V3 WebSocket API for real-time analysis and streamlined performance.

Here's a summary of the Python-relevant WebSocket information from the MEXC API v3 documentation:

General WebSocket Details

Base Endpoint: wss://wbs.mexc.com/ws

Connection Duration: 24 hours (automatic disconnection after that)

Keep-Alive: Send PING messages to maintain the connection.

Symbol Case: All symbols are uppercase (e.g., BTCUSDT).

Subscription Limit: Maximum 30 subscriptions per connection.

Listen Key Duration (User Data Streams): 60 minutes (can be extended with keep-alive requests)

Python SDK

MEXC provides a Python SDK (mexc-api-sdk) for easier interaction with the API:

https://github.com/mexcdevelop/mexc-api-sdk

The SDK likely simplifies WebSocket handling, including connection management, subscriptions, and message parsing. Refer to the SDK documentation for specifics.

Subscribing/Unsubscribing

JSON Payload Structure:

{
    "method": "SUBSCRIPTION" or "UNSUBSCRIPTION",
    "params": ["stream_name1", "stream_name2", ...]
}
content_copy
Use code with caution.
Json

Example (Python):

import json

# Assuming you have a WebSocket connection object `ws`

# Subscribe to a stream
subscription_data = {
    "method": "SUBSCRIPTION",
    "params": ["spot@public.deals.v3.api@BTCUSDT"]
}
ws.send(json.dumps(subscription_data))

# Unsubscribe from a stream
unsubscription_data = {
    "method": "UNSUBSCRIPTION",
    "params": ["spot@public.deals.v3.api@BTCUSDT"] 
}
ws.send(json.dumps(unsubscription_data))
content_copy
Use code with caution.
Python

Important Stream Examples

Market Data:

spot@public.deals.v3.api@BTCUSDT: Trade streams (real-time trade information).

spot@public.kline.v3.api@BTCUSDT@Min15: Kline/Candlestick streams (updates every second).

spot@public.increase.depth.v3.api@BTCUSDT: Diff. Depth stream (incremental order book changes).

User Data:

Requires a Listen Key: Obtain using the POST /api/v3/userDataStream endpoint.

spot@private.account.v3.api: Account updates (balance changes).

spot@private.deals.v3.api: Account deals (your trades).

spot@private.orders.v3.api: Account order updates.

Data Handling in Python

Receive Messages: Use ws.recv() to receive messages from the WebSocket server.

Parse JSON:

import json

message = ws.recv() 
data = json.loads(message) 
# Process the `data` dictionary based on the stream you subscribed to.
content_copy
Use code with caution.
Python

Additional Notes

The MEXC API documentation provides detailed information on the format of data received for each stream.

Explore the Python SDK for more convenient ways to work with WebSockets and manage connections.

Carefully handle rate limits and potential disconnections, especially for user data streams that require listen keys.

Sharing this Information

Feel free to share this summarized information with others. Emphasize the following:

Python SDK: Encourage using the SDK for simplified WebSocket interaction.

Stream Names: Provide clear examples of important stream names.

Data Parsing: Highlight the use of json.loads() for parsing JSON data.

Listen Keys (User Data): Stress the need for listen keys and their limited validity.

Documentation: Direct people to the official MEXC API documentation for comprehensive details.

# MEXC API Configuration- C:\Users\dylan\Desktop\sheeplz-crypto-bot\configs
MEXC_API_KEY=
MEXC_API_SECRET=
MEXC_WS_URL=wss://wbs.mexc.com/ws

// File: data\data_processor.py
import asyncio

class DataProcessor:
    def __init__(self, storage, indicator_calculator, error_handler, config):
        self.storage = storage
        self.indicator_calculator = indicator_calculator
        self.error_handler = error_handler
        self.config = config

    async def process_data(self, data_batch):
        """Processes kline data and applies indicators asynchronously."""
        processed_data = {}
        for data in data_batch:
            try:
                kline_data = self._extract_kline_data(data)
                timeframe = self._get_timeframe(data)
                if timeframe not in processed_data:
                    processed_data[timeframe] = []
                processed_data[timeframe].append(kline_data)
            except Exception as e:
                self.error_handler.handle_error(f"Error extracting kline data: {e}", exc_info=True)

        try:
            indicators = await self._calculate_indicators_async(processed_data)
            unified_feed = self._create_unified_feed(processed_data, indicators)
            await self.storage.store_data(unified_feed)
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating indicators or storing data: {e}", exc_info=True)

    async def _calculate_indicators_async(self, processed_data):
        """Calculates indicators asynchronously."""
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self.indicator_calculator.calculate_indicators, processed_data)

    def _extract_kline_data(self, data):
        # Extract kline data (fill with your logic)
        return {
            'open': data['d']['k']['o'],
            'high': data['d']['k']['h'],
            'low': data['d']['k']['l'],
            'close': data['d']['k']['c'],
            'volume': data['d']['k']['v'],
            'close_time': data['d']['k']['T']
        }

    def _get_timeframe(self, data):
        # Extract timeframe (assuming format is 'spot@public.kline.v3.api@BTCUSDT@kline_1m')
        return data.get('c', '').split('@')[-1].split('_')[-1]

    def _create_unified_feed(self, klines, indicators):
        """Combines kline data and indicators into a unified feed."""
        unified_feed = {}
        for timeframe, data in klines.items():
            unified_feed[timeframe] = {
                'price': [entry['close'] for entry in data],
                'volume': [entry['volume'] for entry in data],
                'open': [entry['open'] for entry in data],
                'high': [entry['high'] for entry in data],
                'low': [entry['low'] for entry in data],
                'close_time': [entry['close_time'] for entry in data],
                'indicators': indicators.get(timeframe, {})
            }
        return unified_feed


// File: data\indicator_calculations.py
import pandas as pd
from finta import TA
from .error_handler import ErrorHandler
from typing import Dict, Any, List
import concurrent.futures

class IndicatorCalculator:
    def __init__(self, error_handler: ErrorHandler):
        """
        Initializes the IndicatorCalculator with an error handler.
        Args:
            error_handler (ErrorHandler): Instance to handle errors during calculations.
        """
        self.error_handler = error_handler

    def calculate_indicators(self, symbol: str, data: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, Any]]:
        """
        Calculates indicators for all timeframes.
        Args:
            symbol (str): The trading symbol (e.g., 'BTC_USDT').
            data (Dict[str, pd.DataFrame]): Dictionary where keys are timeframes and values are DataFrames.
        Returns:
            Dict[str, Dict[str, Any]]: Dictionary of indicators keyed by timeframe.
        """
        indicators = {}
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {executor.submit(self._calculate_for_timeframe, symbol, timeframe, df): timeframe for timeframe, df in data.items()}
                for future in concurrent.futures.as_completed(futures):
                    timeframe = futures[future]
                    try:
                        indicators[timeframe] = future.result()
                    except Exception as e:
                        self.error_handler.handle_error(f"Error calculating indicators for {symbol} {timeframe}: {e}", exc_info=True)
        except Exception as e:
            self.error_handler.handle_error(f"Error in calculate_indicators: {e}", exc_info=True)
        return indicators

    def _calculate_for_timeframe(self, symbol: str, timeframe: str, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Helper function to calculate indicators for a specific timeframe.
        Args:
            symbol (str): The trading symbol (e.g., 'BTC_USDT').
            timeframe (str): The timeframe being processed.
            df (pd.DataFrame): DataFrame containing OHLC data for the timeframe.
        Returns:
            Dict[str, Any]: Calculated indicators for the timeframe.
        """
        indicators = {}
        try:
            # Ensure dataframe has the required columns
            required_columns = ['open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"Missing required columns in {timeframe} data for {symbol}: {df.columns}")

            indicators['rsi'] = self.calculate_rsi(df)
            indicators['macd'] = self.calculate_macd(df)
            indicators['fibonacci'] = self.calculate_fibonacci(df)
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating indicators for {symbol} {timeframe}: {e}", exc_info=True)
        return indicators

    def calculate_rsi(self, df: pd.DataFrame) -> List[float]:
        """
        Calculates the RSI (Relative Strength Index).
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            List[float]: RSI values.
        """
        try:
            rsi_values = TA.RSI(df).fillna(0).tolist()
            return rsi_values
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating RSI: {e}", exc_info=True)
            return []

    def calculate_macd(self, df: pd.DataFrame) -> Dict[str, List[float]]:
        """
        Calculates the MACD (Moving Average Convergence Divergence).
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            Dict[str, List[float]]: MACD values, signal line, and histogram.
        """
        try:
            macd_values = TA.MACD(df).fillna(0)
            return {
                'macd': macd_values['MACD'].tolist(),
                'macd_signal': macd_values['SIGNAL'].tolist(),
                'macd_hist': macd_values['HISTOGRAM'].tolist()
            }
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating MACD: {e}", exc_info=True)
            return {'macd': [], 'macd_signal': [], 'macd_hist': []}

    def calculate_fibonacci(self, df: pd.DataFrame) -> Dict[str, float]:
        """
        Calculates Fibonacci Retracement levels manually.
        Args:
            df (pd.DataFrame): DataFrame containing OHLC data.
        Returns:
            Dict[str, float]: Fibonacci retracement levels.
        """
        try:
            high = df['high'].max()
            low = df['low'].min()
            diff = high - low
            fib_levels = {
                "23.6%": high - 0.236 * diff,
                "38.2%": high - 0.382 * diff,
                "50.0%": high - 0.5 * diff,
                "61.8%": high - 0.618 * diff,
                "78.6%": high - 0.786 * diff
            }
            return fib_levels
        except Exception as e:
            self.error_handler.handle_error(f"Error calculating Fibonacci Retracement: {e}", exc_info=True)
            return {}


// File: data\mexc_websocket_connector.py
import os
import json
import websockets
import asyncio
from dotenv import load_dotenv

load_dotenv()

class MexcWebsocketConnector:
    def __init__(self, data_queue):
        self.ws_url = os.getenv("MEXC_WS_URL", "wss://wbs.mexc.com/ws")
        self.api_key = os.getenv("MEXC_API_KEY")
        self.api_secret = os.getenv("MEXC_API_SECRET")
        self.reconnect_delay = 5.0
        self.data_queue = data_queue

    async def connect(self):
        while True:
            try:
                async with websockets.connect(self.ws_url) as ws:
                    await self._subscribe(ws)
                    await self._receive_batched_klines(ws)
            except Exception as e:
                print(f"WebSocket connection error: {e}")
                await asyncio.sleep(self.reconnect_delay)

    async def _subscribe(self, ws):
        subscribe_message = {
            "method": "SUBSCRIBE",
            "params": ["spot@public.kline.v3.api@BTCUSDT@kline_1m", "spot@public.kline.v3.api@BTCUSDT@kline_5m"],
            "id": 1
        }
        await ws.send(json.dumps(subscribe_message))

    async def _receive_batched_klines(self, ws):
        """Receives and processes kline data in batches."""
        kline_batch = []
        while True:
            try:
                message = await ws.recv()
                data = json.loads(message)
                if "spot@public.kline.v3.api" in data.get("c", ""):
                    kline_batch.append(data)
                else:
                    if kline_batch:
                        await self.data_queue.put(kline_batch)
                        kline_batch = []  # Reset batch
            except Exception as e:
                print(f"Error receiving kline data: {e}")
                break


// File: data\__init__.py
from .mexc_websocket_connector import MexcWebsocketConnector
from .data_processor import DataProcessor
from .storage.data_storage import DataStorage

__all__ = ['MexcWebsocketConnector', 'DataProcessor', 'WebSocketManager', 'DataStorage']


// File: data\storage\data_storage.py
import asyncio
import pandas as pd
import os

class DataStorage:
    def __init__(self, storage_path="data_storage"):
        self.storage_path = storage_path
        os.makedirs(self.storage_path, exist_ok=True)

    async def store_data(self, unified_feed):
        """Stores unified feed data asynchronously."""
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, self._store_data_sync, unified_feed)

    def _store_data_sync(self, unified_feed):
        """Synchronous helper function for data storage."""
        symbol = "BTC_USDT"  # Assuming single symbol; adjust if needed.
        for timeframe, content in unified_feed.items():
            df = pd.DataFrame(content)  # Create DataFrame from content
            filename = f"{symbol}_{timeframe}.csv"
            filepath = os.path.join(self.storage_path, filename)
            df.to_csv(filepath, index=False)
            print(f"Data stored in {filepath}")


// File: data\storage\__init__.py


